<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />









  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="本章中，你会假装作为被一家地产公司刚刚雇佣的数据科学家，完整地学习一个案例项目。下面是主要步骤：">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习笔记|第2章 一个完整的机器学习项目">
<meta property="og:url" content="https://zzy99.github.io/2018/06/05/2.一个完整的机器学习项目/index.html">
<meta property="og:site_name" content="四度空间">
<meta property="og:description" content="本章中，你会假装作为被一家地产公司刚刚雇佣的数据科学家，完整地学习一个案例项目。下面是主要步骤：">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-4af1bd6b259d5b12.png">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-28db35d98205567b.png">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-b78d5d4f64b5a8dc.png">
<meta property="og:image" content="https://zzy99.github.io/2018/06/05/images/tex-e8fa5b806940d1b4d0059fba40646506.gif">
<meta property="og:image" content="https://zzy99.github.io/2018/06/05/images/tex-4be66ad2cf5c98540db20bd7df0c0413.gif">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-25c88114ac85b76c.png">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-e54122a46b09f013.png">
<meta property="og:image" content="https://zzy99.github.io/2018/06/05/images/tex-e8fa5b806940d1b4d0059fba40646506.gif">
<meta property="og:image" content="https://zzy99.github.io/2018/06/05/images/tex-5f35ce35c210c83604c8edc2fddd1660.gif">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-e159cd4395a29dca.png">
<meta property="og:image" content="https://zzy99.github.io/2018/06/05/images/tex-e8fa5b806940d1b4d0059fba40646506.gif">
<meta property="og:image" content="https://zzy99.github.io/2018/06/05/images/tex-003d289de50330b0e7b49f10b89376a1.gif">
<meta property="og:image" content="https://zzy99.github.io/2018/06/05/images/tex-13ada0b94f610ad731b13dd5262af022.gif">
<meta property="og:image" content="https://zzy99.github.io/2018/06/05/images/tex-1a3f1413f9e9a5f7fec99ac5f57eed2d.gif">
<meta property="og:image" content="https://zzy99.github.io/2018/06/05/images/tex-b696d3a200c2cdc2fb9b2c143925beb4.gif">
<meta property="og:image" content="https://zzy99.github.io/2018/06/05/images/tex-bac2029f70ce6a6b273b169d1692b55d.gif">
<meta property="og:image" content="https://zzy99.github.io/2018/06/05/images/tex-9907535e0085e9baa59eba3a390ac093.gif">
<meta property="og:image" content="https://zzy99.github.io/2018/06/05/images/tex-8697a40b91a9a08aa05beb034db77d85.gif">
<meta property="og:image" content="https://zzy99.github.io/2018/06/05/images/tex-b60c884daed2610a13fbb7c142944314.gif">
<meta property="og:image" content="https://zzy99.github.io/2018/06/05/images/tex-3071526a1b0f8639644eaba81ce73a74.gif">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-dc7dc324c5399c23.png">
<meta property="og:image" content="https://zzy99.github.io/2018/06/05/images/tex-faf4895169e5f2dd47098981399efe8e.gif">
<meta property="og:image" content="https://zzy99.github.io/2018/06/05/images/tex-77c337a8416826e165d9a72bdaf83a45.gif">
<meta property="og:image" content="https://zzy99.github.io/2018/06/05/images/tex-84210ce87d4f53cbece29bfc7691aceb.gif">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-b3436479a2b527c0.png">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-4b45dc192b2d4c54.png">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-9bdc2af5a6f6dddf.png">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-07fc05ab3c9e5802.png">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-deacf48a4fb98035.png">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-bf3e4d22b4b8a33d.png">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-ff8dbaa59c716560.png">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-6f5f192c61bd9806.png">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-6aaaf5a4dfe511a5.png">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-90fa1be435569d25.png">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-cb9bec05a3d2ddca.png">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-017573305488b4da.png">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-40836bf268955df7.png">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-9260352458302ba0.png">
<meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7178691-2b0b2ac071f62636.png">
<meta property="og:updated_time" content="2018-06-05T14:36:25.284Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习笔记|第2章 一个完整的机器学习项目">
<meta name="twitter:description" content="本章中，你会假装作为被一家地产公司刚刚雇佣的数据科学家，完整地学习一个案例项目。下面是主要步骤：">
<meta name="twitter:image" content="https://upload-images.jianshu.io/upload_images/7178691-4af1bd6b259d5b12.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://zzy99.github.io/2018/06/05/2.一个完整的机器学习项目/"/>





  <title>机器学习笔记|第2章 一个完整的机器学习项目 | 四度空间</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">四度空间</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">朱政烨的BLOG</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            目录
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://zzy99.github.io/2018/06/05/2.一个完整的机器学习项目/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="朱政烨">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="四度空间">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">机器学习笔记|第2章 一个完整的机器学习项目</h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-05T00:00:00+08:00">
                2018-06-05
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-06-05T22:36:25+08:00">
                2018-06-05
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/06/05/2.一个完整的机器学习项目/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/06/05/2.一个完整的机器学习项目/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>本章中，你会假装作为被一家地产公司刚刚雇佣的数据科学家，完整地学习一个案例项目。下面是主要步骤：<br><a id="more"></a></p>
<ol>
<li>项目概述。</li>
<li>获取数据。</li>
<li>发现并可视化数据，发现规律。</li>
<li>为机器学习算法准备数据。</li>
<li>选择模型，进行训练。</li>
<li>微调模型。</li>
<li>给出解决方案。</li>
<li>部署、监控、维护系统。</li>
</ol>
<h2 id="使用真实数据"><a href="#使用真实数据" class="headerlink" title="使用真实数据"></a>使用真实数据</h2><p>学习机器学习时，最好使用真实数据，而不是人工数据集。幸运的是，有上千个开源数据集可以进行选择，涵盖多个领域。以下是一些可以查找的数据的地方：</p>
<ul>
<li>流行的开源数据仓库：<ul>
<li><a href="https://link.jianshu.com?t=http%3A%2F%2Farchive.ics.uci.edu%2Fml%2F" target="_blank" rel="noopener">UC Irvine Machine Learning Repository</a>  </li>
<li><a href="https://link.jianshu.com?t=https%3A%2F%2Fwww.kaggle.com%2Fdatasets" target="_blank" rel="noopener">Kaggle datasets</a>  </li>
<li><a href="https://link.jianshu.com?t=http%3A%2F%2Faws.amazon.com%2Ffr%2Fdatasets%2F" target="_blank" rel="noopener">Amazon’s AWS datasets</a></li>
</ul>
</li>
<li>准入口（提供开源数据列表）  <ul>
<li><a href="https://link.jianshu.com?t=http%3A%2F%2Fdataportals.org%2F" target="_blank" rel="noopener">http://dataportals.org/</a>  </li>
<li><a href="https://link.jianshu.com?t=http%3A%2F%2Fopendatamonitor.eu%2F" target="_blank" rel="noopener">http://opendatamonitor.eu/</a>  </li>
<li><a href="https://link.jianshu.com?t=http%3A%2F%2Fquandl.com%2F" target="_blank" rel="noopener">http://quandl.com/</a></li>
</ul>
</li>
<li>其它列出流行开源数据仓库的网页：  <ul>
<li><a href="https://link.jianshu.com?t=https%3A%2F%2Fgoo.gl%2FSJHN2k" target="_blank" rel="noopener">Wikipedia’s list of Machine Learning datasets</a>  </li>
<li><a href="https://link.jianshu.com?t=http%3A%2F%2Fgoo.gl%2FzDR78y" target="_blank" rel="noopener">Quora.com question</a>  </li>
<li><a href="https://link.jianshu.com?t=https%3A%2F%2Fwww.reddit.com%2Fr%2Fdatasets" target="_blank" rel="noopener">Datasets subreddit</a></li>
</ul>
</li>
</ul>
<p>本章，我们选择的是 StatLib 的加州房产价格数据集（见图 2-1）。这个数据集是基于 1990 年加州普查的数据。数据已经有点老（1990 年还能买一个湾区不错的房子），但是它有许多优点，利于学习，所以假设这个数据为最近的。为了便于教学，我们添加了一个类别属性，并除去了一些。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-4af1bd6b259d5b12.png" alt=""></p>
<p>图 2-1 加州房产价格</p>
<h2 id="项目概览"><a href="#项目概览" class="headerlink" title="项目概览"></a>项目概览</h2><p>欢迎来到机器学习房地产公司！你的第一个任务是利用加州普查数据，建立一个加州房价模型。这个数据包含每个街区组的人口、收入中位数、房价中位数等指标。</p>
<p>街区组是美国调查局发布样本数据的最小地理单位（一个街区通常有 600 到 3000 人）。我们将其简称为“街区”。</p>
<p>你的模型要利用这个数据进行学习，然后根据其它指标，预测任何街区的的房价中位数。</p>
<blockquote>
<p>提示：你是一个有条理的数据科学家，你要做的第一件事是拿出你的机器学习项目清单。你可以使用附录 B 中的清单；这个清单适用于大多数的机器学习项目，但是你还是要确认它是否满足需求。在本章中，我们会检查许多清单上的项目，但是也会跳过一些简单的，有些会在后面的章节再讨论。</p>
</blockquote>
<h3 id="划定问题"><a href="#划定问题" class="headerlink" title="划定问题"></a>划定问题</h3><p>问老板的第一个问题应该是商业目标是什么？建立模型可能不是最终目标。公司要如何使用、并从模型受益？这非常重要，因为它决定了如何划定问题，要选择什么算法，评估模型性能的指标是什么，要花多少精力进行微调。</p>
<p>老板告诉你你的模型的输出（一个区的房价中位数）会传给另一个机器学习系统（见图 2-2），也有其它信号会传入后面的系统。这一整套系统可以确定某个区进行投资值不值。确定值不值得投资非常重要，它直接影响利润。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-28db35d98205567b.png" alt=""></p>
<p>图 2-2 房地产投资的机器学习流水线</p>
<blockquote>
<p>流水线  </p>
<p>一系列的数据处理组件被称为数据流水线。流水线在机器学习系统中很常见，因为有许多数据要处理和转换。</p>
<p>组件通常是异步运行的。每个组件吸纳进大量数据，进行处理，然后将数据传输到另一个数据容器中，而后流水线中的另一个组件收入这个数据，然后输出，这个过程依次进行下去。每个组件都是独立的：组件间的接口只是数据容器。这样可以让系统更便于理解（记住数据流的图），不同的项目组可以关注于不同的组件。进而，如果一个组件失效了，下游的组件使用失效组件最后生产的数据，通常可以正常运行（一段时间）。这样就使整个架构相当健壮。</p>
<p>另一方面，如果没有监控，失效的组件会在不被注意的情况下运行一段时间。数据会受到污染，整个系统的性能就会下降。</p>
</blockquote>
<p>下一个要问的问题是，现在的解决方案效果如何。老板通常会给一个参考性能，以及如何解决问题。老板说，现在街区的房价是靠专家手工估计的，专家队伍收集最新的关于一个区的信息（不包括房价中位数），他们使用复杂的规则进行估计。这种方法费钱费时间，而且估计结果不理想，误差率大概有 15%。</p>
<p>OK，有了这些信息，你就可以开始设计系统了。首先，你需要划定问题：监督或非监督，还是强化学习？这是个分类任务、回归任务，还是其它的？要使用批量学习还是线上学习？继续阅读之前，请暂停一下，尝试自己回答下这些问题。</p>
<p>你能回答出来吗？一起看下答案：很明显，这是一个典型的监督学习任务，因为你要使用的是有标签的训练样本（每个实例都有预定的产出，即街区的房价中位数）。并且，这是一个典型的回归任务，因为你要预测一个值。讲的更细些，这是一个多变量回归问题，因为系统要使用多个变量进行预测（要使用街区的人口，收入中位数等等）。在第一章中，你只是根据人均 GDP 来预测生活满意度，因此这是一个单变量回归问题。最后，没有连续的数据流进入系统，没有特别需求需要对数据变动作出快速适应。数据量不大可以放到内存中，因此批量学习就够了。</p>
<blockquote>
<p>提示：如果数据量很大，你可以要么在多个服务器上对批量学习做拆分（使用 MapReduce 技术，后面会看到），或是使用线上学习。</p>
</blockquote>
<h3 id="选择性能指标"><a href="#选择性能指标" class="headerlink" title="选择性能指标"></a>选择性能指标</h3><p>下一步是选择性能指标。回归问题的典型指标是均方根误差（RMSE）。均方根误差测量的是系统预测误差的标准差。例如，RMSE 等于 50000，意味着，68% 的系统预测值位于实际值的 50000 美元以内，95% 的预测值位于实际值的 100000 美元以内（一个特征通常都符合高斯分布，即满足 “68-95-99.7”规则：大约68%的值落在<code>1σ</code>内，95% 的值落在<code>2σ</code>内，99.7%的值落在<code>3σ</code>内，这里的<code>σ</code>等于50000）。公式 2-1 展示了计算 RMSE 的方法。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-b78d5d4f64b5a8dc.png" alt=""></p>
<p>公式 2-1 均方根误差（RMSE）</p>
<blockquote>
<p>符号的含义</p>
<p>这个方程引入了一些常见的贯穿本书的机器学习符号：</p>
<ul>
<li><p><code>m</code>是测量 RMSE 的数据集中的实例数量。<br>  例如，如果用一个含有 2000 个街区的验证集求 RMSE，则<code>m = 2000</code>。</p>
</li>
<li><p><img src="../images/tex-e8fa5b806940d1b4d0059fba40646506.gif" alt="x^{(i)}"> 是数据集第<code>i</code>个实例的所有特征值（不包含标签）的向量，<img src="../images/tex-4be66ad2cf5c98540db20bd7df0c0413.gif" alt="y^{(i)}"> 是它的标签（这个实例的输出值）。 </p>
<p>  例如，如果数据集中的第一个街区位于经度 –118.29°，纬度 33.91°，有 1416 名居民，收入中位数是 38372 美元，房价中位数是 156400 美元（忽略掉其它的特征），则有：  </p>
<p>  <img src="https://upload-images.jianshu.io/upload_images/7178691-25c88114ac85b76c.png" alt=""></p>
<p>  和，  </p>
<p>  <img src="https://upload-images.jianshu.io/upload_images/7178691-e54122a46b09f013.png" alt=""></p>
</li>
<li><p><code>X</code>是包含数据集中所有实例的所有特征值（不包含标签）的矩阵。每一行是一个实例，第<code>i</code>行是 <img src="../images/tex-e8fa5b806940d1b4d0059fba40646506.gif" alt="x^{(i)}"> 的转置，记为 <img src="../images/tex-5f35ce35c210c83604c8edc2fddd1660.gif" alt="x^{(i)T}">。</p>
<p>例如，仍然是前面提到的第一区，矩阵<code>X</code>就是：  </p>
<p>  <img src="https://upload-images.jianshu.io/upload_images/7178691-e159cd4395a29dca.png" alt=""></p>
</li>
<li><p><code>h</code>是系统的预测函数，也称为假设（hypothesis）。当系统收到一个实例的特征向量 <img src="../images/tex-e8fa5b806940d1b4d0059fba40646506.gif" alt="x^{(i)}">，就会输出这个实例的一个预测值 <img src="../images/tex-003d289de50330b0e7b49f10b89376a1.gif" alt="\hat y^{(i)} = h(x^{(i)})">（<img src="../images/tex-13ada0b94f610ad731b13dd5262af022.gif" alt="\hat y"> 读作<code>y-hat</code>）。  </p>
<p>  例如，如果系统预测第一区的房价中位数是 158400 美元，则 <img src="../images/tex-1a3f1413f9e9a5f7fec99ac5f57eed2d.gif" alt="\hat y^{(1)} = h(x^{(1)}) = 158400">。预测误差是 <img src="../images/tex-b696d3a200c2cdc2fb9b2c143925beb4.gif" alt="\hat y^{(1)} – y^{(1)} = 2000">。</p>
</li>
<li><p><code>RMSE(X,h)</code>是使用假设<code>h</code>在样本集上测量的损失函数。</p>
</li>
</ul>
<p>我们使用小写斜体表示标量值（例如 <img src="../images/tex-bac2029f70ce6a6b273b169d1692b55d.gif" alt="\it m"> 或 <img src="../images/tex-9907535e0085e9baa59eba3a390ac093.gif" alt="\it{y^{(i)}}">）和函数名（例如 <img src="../images/tex-8697a40b91a9a08aa05beb034db77d85.gif" alt="\it h">），小写粗体表示向量（例如 <img src="../images/tex-b60c884daed2610a13fbb7c142944314.gif" alt="\bb{x^{(i)}}">），大写粗体表示矩阵（例如 <img src="../images/tex-3071526a1b0f8639644eaba81ce73a74.gif" alt="\bb{X}">）。</p>
</blockquote>
<p>虽然大多数时候 RMSE 是回归任务可靠的性能指标，在有些情况下，你可能需要另外的函数。例如，假设存在许多异常的街区。此时，你可能需要使用平均绝对误差（Mean Absolute Error，也称作平均绝对偏差），见公式 2-2：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-dc7dc324c5399c23.png" alt=""></p>
<p>公式2-2 平均绝对误差</p>
<p>RMSE 和 MAE 都是测量预测值和目标值两个向量距离的方法。有多种测量距离的方法，或范数：</p>
<ul>
<li><p>计算对应欧几里得范数的平方和的根（RMSE）：这个距离介绍过。它也称作<code>ℓ2</code>范数，标记为 <img src="../images/tex-faf4895169e5f2dd47098981399efe8e.gif" alt="\| \cdot \|_2">（或只是 <img src="../images/tex-77c337a8416826e165d9a72bdaf83a45.gif" alt="\| \cdot \|">）。</p>
</li>
<li><p>计算对应于<code>ℓ1</code>（标记为 <img src="../images/tex-84210ce87d4f53cbece29bfc7691aceb.gif" alt="\| \cdot \|_1">）范数的绝对值和（MAE）。有时，也称其为曼哈顿范数，因为它测量了城市中的两点，沿着矩形的边行走的距离。</p>
</li>
<li><p>更一般的，包含<code>n</code>个元素的向量<code>v</code>的<code>ℓk</code>范数（K 阶闵氏范数），定义成</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-b3436479a2b527c0.png" alt=""></p>
<p><code>ℓ0</code>（汉明范数）只显示了这个向量的基数（即，非零元素的个数），<code>ℓ∞</code>（切比雪夫范数）是向量中最大的绝对值。</p>
</li>
<li><p>范数的指数越高，就越关注大的值而忽略小的值。这就是为什么 RMSE 比 MAE 对异常值更敏感。但是当异常值是指数分布的（类似正态曲线），RMSE 就会表现很好。</p>
</li>
</ul>
<h3 id="核实假设"><a href="#核实假设" class="headerlink" title="核实假设"></a>核实假设</h3><p>最后，最好列出并核对迄今（你或其他人）作出的假设，这样可以尽早发现严重的问题。例如，你的系统输出的街区房价，会传入到下游的机器学习系统，我们假设这些价格确实会被当做街区房价使用。但是如果下游系统实际上将价格转化成了分类（例如，便宜、中等、昂贵），然后使用这些分类，而不是使用价格。这样的话，获得准确的价格就不那么重要了，你只需要得到合适的分类。问题相应地就变成了一个分类问题，而不是回归任务。你可不想在一个回归系统上工作了数月，最后才发现真相。</p>
<p>幸运的是，在与下游系统主管探讨之后，你很确信他们需要的就是实际的价格，而不是分类。很好！整装待发，可以开始写代码了。</p>
<h2 id="获取数据"><a href="#获取数据" class="headerlink" title="获取数据"></a>获取数据</h2><p>开始动手。最后用 Jupyter notebook 完整地敲一遍示例代码。完整的代码位于 <a href="https://github.com/ageron/handson-ml" target="_blank" rel="noopener">https://github.com/ageron/handson-ml</a>。</p>
<h3 id="创建工作空间"><a href="#创建工作空间" class="headerlink" title="创建工作空间"></a>创建工作空间</h3><p>首先，你需要安装 Python。可能已经安装过了，没有的话，可以从官网下载 <a href="https://www.python.org/" target="_blank" rel="noopener">https://www.python.org/</a>。</p>
<p>接下来，需要为你的机器学习代码和数据集创建工作空间目录。打开一个终端，输入以下命令（在提示符<code>$</code>之后）：</p>
<pre>
&#x24; export ML_PATH="&#x24;HOME/ml"      # 可以更改路径
&#x24; mkdir -p &#x24;ML_PATH
</pre>

<p>还需要一些 Python 模块：Jupyter、NumPy、Pandas、Matplotlib 和 Scikit-Learn。如果所有这些模块都已经在 Jupyter 中运行了，你可以直接跳到下一节“下载数据”。如果还没安装，有多种方法可以进行安装（包括它们的依赖）。你可以使用系统的包管理系统（比如 Ubuntu 上的<code>apt-get</code>，或 macOS 上的 MacPorts 或 HomeBrew），安装一个 Python 科学计算环境比如 Anaconda，使用 Anaconda 的包管理系统，或者使用 Python 自己的包管理器<code>pip</code>，它是 Python 安装包（自从 2.7.9 版本）自带的。可以用下面的命令检测是否安装<code>pip</code>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ pip3 --version</span><br><span class="line">pip 9.0.1 from [...]/lib/python3.5/site-packages (python 3.5)</span><br></pre></td></tr></table></figure>
<p>你需要保证<code>pip</code>是近期的版本，至少高于 1.4，以保障二进制模块文件的安装（也称为 wheel）。要升级<code>pip</code>，可以使用下面的命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ pip3 install --upgrade pip</span><br><span class="line">Collecting pip</span><br><span class="line">[...]</span><br><span class="line">Successfully installed pip-9.0.1</span><br></pre></td></tr></table></figure>
<blockquote>
<p>创建独立环境</p>
<p>如果你希望在一个独立环境中工作（强烈推荐这么做，不同项目的库的版本不会冲突），用下面的<code>pip</code>命令安装<code>virtualenv</code>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; $ pip3 install --user --upgrade virtualenv</span><br><span class="line">&gt; Collecting virtualenv</span><br><span class="line">&gt; [...]</span><br><span class="line">&gt; Successfully installed virtualenv</span><br><span class="line">&gt; </span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<blockquote>
<p>现在可以通过下面命令创建一个独立的 Python 环境：</p>
<pre>&#x24; cd &#x24;ML_PATH<br>&#x24; virtualenv env<br>Using base prefix '[...]'<br>New python executable in [...]/ml/env/bin/python3.5<br>Also creating executable in [...]/ml/env/bin/python<br>Installing setuptools, pip, wheel...done.</pre>

<p>以后每次想要激活这个环境,只需打开一个终端然后输入：</p>
<pre>&#x24; cd &#x24;ML_PATH<br>&#x24; source env/bin/activate</pre>

<p>启动该环境时，使用<code>pip</code>安装的任何包都只安装于这个独立环境中，Python 指挥访问这些包（如果你希望 Python 能访问系统的包，创建环境时要使用包选项<code>--system-site</code>）。更多信息，请查看<code>virtualenv</code>文档。</p>
</blockquote>
<p>现在，你可以使用<code>pip</code>命令安装所有必需的模块和它们的依赖：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ pip3 install --upgrade jupyter matplotlib numpy pandas scipy scikit-learn</span><br><span class="line">Collecting jupyter</span><br><span class="line">  Downloading jupyter-1.0.0-py2.py3-none-any.whl</span><br><span class="line">Collecting matplotlib</span><br><span class="line">  [...]</span><br></pre></td></tr></table></figure>
<p>要检查安装，可以用下面的命令引入每个模块：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ python3 -c &quot;import jupyter, matplotlib, numpy, pandas, scipy, sklearn&quot;</span><br></pre></td></tr></table></figure>
<p>这个命令不应该有任何输出和错误。现在你可以用下面的命令打开 Jupyter：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ jupyter notebook</span><br><span class="line">[I 15:24 NotebookApp] Serving notebooks from local directory: [...]/ml</span><br><span class="line">[I 15:24 NotebookApp] 0 active kernels</span><br><span class="line">[I 15:24 NotebookApp] The Jupyter Notebook is running at: http://localhost:8888/</span><br><span class="line">[I 15:24 NotebookApp] Use Control-C to stop this server and shut down all</span><br><span class="line">kernels (twice to skip confirmation).</span><br></pre></td></tr></table></figure>
<p>Jupyter 服务器现在运行在终端上，监听 888 8端口。你可以用浏览器打开<code>http://localhost:8888/</code>，以访问这个服务器（服务器启动时，通常就自动打开了）。你可以看到一个空的工作空间目录（如果按照先前的<code>virtualenv</code>步骤，只包含<code>env</code>目录）。</p>
<p>现在点击按钮 New 创建一个新的 Python 注本，选择合适的 Python 版本（见图 2-3）。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-4b45dc192b2d4c54.png" alt=""></p>
<p>图 2-3 Jupyter 的工作空间</p>
<p>这一步做了三件事：首先，在工作空间中创建了一个新的 notebook 文件<code>Untitled.ipynb</code>；第二，它启动了一个 Jupyter 的 Python 内核来运行这个 notebook；第三，在一个新栏中打开这个 notebook。接下来，点击 Untitled，将这个 notebook 重命名为<code>Housing</code>（这会将<code>ipynb</code>文件自动命名为<code>Housing.ipynb</code>）。</p>
<p>notebook 包含一组代码框。每个代码框可以放入可执行代码或格式化文本。现在，notebook 只有一个空的代码框，标签是<code>In [1]:</code>。在框中输入<code>print(&quot;Hello world!&quot;)</code>，点击运行按钮（见图 2-4）或按<code>Shift+Enter</code>。这会将当前的代码框发送到 Python 内核，运行之后会返回输出。结果显示在代码框下方。由于抵达了 notebook 的底部，一个新的代码框会被自动创建出来。从 Jupyter 的 Help 菜单中的 User Interface Tour，可以学习 Jupyter 的基本操作。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-9bdc2af5a6f6dddf.png" alt=""></p>
<p>图 2-4 在 notebook 中打印<code>Hello world!</code></p>
<h3 id="下载数据"><a href="#下载数据" class="headerlink" title="下载数据"></a>下载数据</h3><p>一般情况下，数据是存储于关系型数据库（或其它常见数据库）中的多个表、文档、文件。要访问数据，你首先要有密码和登录权限，并要了解数据模式。但是在这个项目中，这一切要简单些：只要下载一个压缩文件，<code>housing.tgz</code>，它包含一个 CSV 文件<code>housing.csv</code>，含有所有数据。</p>
<p>你可以使用浏览器下载，运行<code>tar xzf housing.tgz</code>解压出<code>csv</code>文件，但是更好的办法是写一个小函数来做这件事。如果数据变动频繁，这么做是非常好的，因为可以让你写一个小脚本随时获取最新的数据（或者创建一个定时任务来做）。如果你想在多台机器上安装数据集，获取数据自动化也是非常好的。</p>
<p>下面是获取数据的函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> tarfile</span><br><span class="line"><span class="keyword">from</span> six.moves <span class="keyword">import</span> urllib</span><br><span class="line"></span><br><span class="line">DOWNLOAD_ROOT = <span class="string">"https://raw.githubusercontent.com/ageron/handson-ml/master/"</span></span><br><span class="line">HOUSING_PATH = <span class="string">"datasets/housing"</span></span><br><span class="line">HOUSING_URL = DOWNLOAD_ROOT + HOUSING_PATH + <span class="string">"/housing.tgz"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fetch_housing_data</span><span class="params">(housing_url=HOUSING_URL, housing_path=HOUSING_PATH)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(housing_path):</span><br><span class="line">        os.makedirs(housing_path)</span><br><span class="line">    tgz_path = os.path.join(housing_path, <span class="string">"housing.tgz"</span>)</span><br><span class="line">    urllib.request.urlretrieve(housing_url, tgz_path)</span><br><span class="line">    housing_tgz = tarfile.open(tgz_path)</span><br><span class="line">    housing_tgz.extractall(path=housing_path)</span><br><span class="line">    housing_tgz.close()</span><br></pre></td></tr></table></figure>
<p>现在，当你调用<code>fetch_housing_data()</code>，就会在工作空间创建一个<code>datasets/housing</code>目录，下载<code>housing.tgz</code>文件，解压出<code>housing.csv</code>。</p>
<p>然后使用Pandas加载数据。还是用一个小函数来加载数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_housing_data</span><span class="params">(housing_path=HOUSING_PATH)</span>:</span></span><br><span class="line">    csv_path = os.path.join(housing_path, <span class="string">"housing.csv"</span>)</span><br><span class="line">    <span class="keyword">return</span> pd.read_csv(csv_path)</span><br></pre></td></tr></table></figure>
<p>这个函数会返回一个包含所有数据的 Pandas <code>DataFrame</code> 对象。</p>
<h3 id="快速查看数据结构"><a href="#快速查看数据结构" class="headerlink" title="快速查看数据结构"></a>快速查看数据结构</h3><p>使用<code>DataFrame</code>的<code>head()</code>方法查看该数据集的前5行（见图 2-5）。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-07fc05ab3c9e5802.png" alt=""></p>
<p>图 2-5 数据集的前五行</p>
<p>每一行都表示一个街区。共有 10 个属性（截图中可以看到 6 个）：经度、维度、房屋年龄中位数、总房间数、总卧室数、人口数、家庭数、收入中位数、房屋价值中位数、离大海距离。</p>
<p><code>info()</code>方法可以快速查看数据的描述，特别是总行数、每个属性的类型和非空值的数量（见图 2-6）。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-deacf48a4fb98035.png" alt=""></p>
<p>图 2-6 房屋信息</p>
<p>数据集中共有 20640 个实例，按照机器学习的标准这个数据量很小，但是非常适合入门。我们注意到总房间数只有 20433 个非空值，这意味着有 207 个街区缺少这个值。我们将在后面对它进行处理。</p>
<p>所有的属性都是数值的，除了离大海距离这项。它的类型是对象，因此可以包含任意 Python 对象，但是因为该项是从 CSV 文件加载的，所以必然是文本类型。在刚才查看数据前五项时，你可能注意到那一列的值是重复的，意味着它可能是一项表示类别的属性。可以使用<code>value_counts()</code>方法查看该项中都有哪些类别，每个类别中都包含有多少个街区：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing[<span class="string">"ocean_proximity"</span>].value_counts()</span><br><span class="line">&lt;<span class="number">1</span>H OCEAN     <span class="number">9136</span></span><br><span class="line">INLAND        <span class="number">6551</span></span><br><span class="line">NEAR OCEAN    <span class="number">2658</span></span><br><span class="line">NEAR BAY      <span class="number">2290</span></span><br><span class="line">ISLAND           <span class="number">5</span></span><br><span class="line">Name: ocean_proximity, dtype: int64</span><br></pre></td></tr></table></figure>
<p>再来看其它字段。<code>describe()</code>方法展示了数值属性的概括（见图 2-7）。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-bf3e4d22b4b8a33d.png" alt=""></p>
<p>图 2-7 每个数值属性的概括</p>
<p><code>count</code>、<code>mean</code>、<code>min</code>和<code>max</code>几行的意思很明显了。注意，空值被忽略了（所以，卧室总数是 20433 而不是 20640）。<code>std</code>是标准差（揭示数值的分散度）。25%、50%、75% 展示了对应的分位数：每个分位数指明小于这个值，且指定分组的百分比。例如，25% 的街区的房屋年龄中位数小于 18，而 50% 的小于 29，75% 的小于 37。这些值通常称为第 25 个百分位数（或第一个四分位数），中位数，第 75 个百分位数（第三个四分位数）。</p>
<p>另一种快速了解数据类型的方法是画出每个数值属性的柱状图。柱状图（的纵轴）展示了特定范围的实例的个数。你还可以一次给一个属性画图，或对完整数据集调用<code>hist()</code>方法，后者会画出每个数值属性的柱状图（见图 2-8）。例如，你可以看到略微超过 800 个街区的<code>median_house_value</code>值差不多等于 500000 美元。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline   <span class="comment"># only in a Jupyter notebook</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">housing.hist(bins=<span class="number">50</span>, figsize=(<span class="number">20</span>,<span class="number">15</span>))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-ff8dbaa59c716560.png" alt=""></p>
<p>图 2-8 每个数值属性的柱状图</p>
<blockquote>
<p>注：<code>hist()</code>方法依赖于 Matplotlib，后者依赖于用户指定的图形后端以打印到屏幕上。因此在画图之前，你要指定 Matplotlib 要使用的后端。最简单的方法是使用 Jupyter 的魔术命令<code>%matplotlib inline</code>。它会告诉 Jupyter 设定好 Matplotlib，以使用 Jupyter 自己的后端。绘图就会在 notebook 中渲染了。注意在 Jupyter 中调用<code>show()</code>不是必要的，因为代码框执行后 Jupyter 会自动展示图像。</p>
</blockquote>
<p>注意柱状图中的一些点：</p>
<ol>
<li><p>首先，收入中位数貌似不是美元（USD）。与数据采集团队交流之后，你被告知数据是经过缩放调整的，过高收入中位数的会变为 15（实际为 15.0001），过低的会变为 5（实际为 0.4999）。在机器学习中对数据进行预处理很正常，这不一定是个问题，但你要明白数据是如何计算出来的。</p>
</li>
<li><p>房屋年龄中位数和房屋价值中位数也被设了上限。后者可能是个严重的问题，因为它是你的目标属性（你的标签）。你的机器学习算法可能学习到价格不会超出这个界限。你需要与下游团队核实，这是否会成为问题。如果他们告诉你他们需要明确的预测值，即使超过 500000 美元，你则有两个选项： </p>
<ol>
<li>对于设了上限的标签，重新收集合适的标签；  </li>
<li>将这些街区从训练集移除（也从测试集移除，因为若房价超出 500000 美元，你的系统就会被差评）。</li>
</ol>
</li>
<li><p>这些属性值有不同的量度。我们会在本章后面讨论特征缩放。</p>
</li>
<li><p>最后，许多柱状图的尾巴很长：相较于左边，它们在中位数的右边延伸过远。对于某些机器学习算法，这会使检测规律变得更难些。我们会在后面尝试变换处理这些属性，使其变为正态分布。</p>
</li>
</ol>
<p>希望你现在对要处理的数据有一定了解了。</p>
<blockquote>
<p>警告：稍等！在你进一步查看数据之前，你需要创建一个测试集，将它放在一旁，千万不要再看它。</p>
</blockquote>
<h3 id="创建测试集"><a href="#创建测试集" class="headerlink" title="创建测试集"></a>创建测试集</h3><p>在这个阶段就分割数据，听起来很奇怪。毕竟，你只是简单快速地查看了数据而已，你需要再仔细调查下数据以决定使用什么算法。这么想是对的，但是人类的大脑是一个神奇的发现规律的系统，这意味着大脑非常容易发生过拟合：如果你查看了测试集，就会不经意地按照测试集中的规律来选择某个特定的机器学习模型。再当你使用测试集来评估误差率时，就会导致评估过于乐观，而实际部署的系统表现就会差。这称为数据透视偏差。</p>
<p>理论上，创建测试集很简单：只要随机挑选一些实例，一般是数据集的 20%，放到一边：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_train_test</span><span class="params">(data, test_ratio)</span>:</span></span><br><span class="line">    shuffled_indices = np.random.permutation(len(data))</span><br><span class="line">    test_set_size = int(len(data) * test_ratio)</span><br><span class="line">    test_indices = shuffled_indices[:test_set_size]</span><br><span class="line">    train_indices = shuffled_indices[test_set_size:]</span><br><span class="line">    <span class="keyword">return</span> data.iloc[train_indices], data.iloc[test_indices]</span><br></pre></td></tr></table></figure>
<p>然后可以像下面这样使用这个函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>train_set, test_set = split_train_test(housing, <span class="number">0.2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(len(train_set), <span class="string">"train +"</span>, len(test_set), <span class="string">"test"</span>)</span><br><span class="line"><span class="number">16512</span> train + <span class="number">4128</span> test</span><br></pre></td></tr></table></figure>
<p>这个方法可行，但是并不完美：如果再次运行程序，就会产生一个不同的测试集！多次运行之后，你（或你的机器学习算法）就会得到整个数据集，这是需要避免的。</p>
<p>解决的办法之一是保存第一次运行得到的测试集，并在随后的过程加载。另一种方法是在调用<code>np.random.permutation()</code>之前，设置随机数生成器的种子（比如<code>np.random.seed(42)</code>），以产生总是相同的洗牌指数（shuffled indices）。</p>
<p>但是如果数据集更新，这两个方法都会失效。一个通常的解决办法是使用每个实例的ID来判定这个实例是否应该放入测试集（假设每个实例都有唯一并且不变的ID）。例如，你可以计算出每个实例ID的哈希值，只保留其最后一个字节，如果该值小于等于 51（约为 256 的 20%），就将其放入测试集。这样可以保证在多次运行中，测试集保持不变，即使更新了数据集。新的测试集会包含新实例中的 20%，但不会有之前位于训练集的实例。下面是一种可用的方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_set_check</span><span class="params">(identifier, test_ratio, hash)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> hash(np.int64(identifier)).digest()[<span class="number">-1</span>] &lt; <span class="number">256</span> * test_ratio</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_train_test_by_id</span><span class="params">(data, test_ratio, id_column, hash=hashlib.md5)</span>:</span></span><br><span class="line">    ids = data[id_column]</span><br><span class="line">    in_test_set = ids.apply(<span class="keyword">lambda</span> id_: test_set_check(id_, test_ratio, hash))</span><br><span class="line">    <span class="keyword">return</span> data.loc[~in_test_set], data.loc[in_test_set]</span><br></pre></td></tr></table></figure>
<p>不过，房产数据集没有ID这一列。最简单的方法是使用行索引作为 ID：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">housing_with_id = housing.reset_index()   <span class="comment"># adds an `index` column</span></span><br><span class="line">train_set, test_set = split_train_test_by_id(housing_with_id, <span class="number">0.2</span>, <span class="string">"index"</span>)</span><br></pre></td></tr></table></figure>
<p>如果使用行索引作为唯一识别码，你需要保证新数据都放到现有数据的尾部，且没有行被删除。如果做不到，则可以用最稳定的特征来创建唯一识别码。例如，一个区的维度和经度在几百万年之内是不变的，所以可以将两者结合成一个 ID：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">housing_with_id[<span class="string">"id"</span>] = housing[<span class="string">"longitude"</span>] * <span class="number">1000</span> + housing[<span class="string">"latitude"</span>]</span><br><span class="line">train_set, test_set = split_train_test_by_id(housing_with_id, <span class="number">0.2</span>, <span class="string">"id"</span>)</span><br></pre></td></tr></table></figure>
<p>Scikit-Learn 提供了一些函数，可以用多种方式将数据集分割成多个子集。最简单的函数是<code>train_test_split</code>，它的作用和之前的函数<code>split_train_test</code>很像，并带有其它一些功能。首先，它有一个<code>random_state</code>参数，可以设定前面讲过的随机生成器种子；第二，你可以将种子传递给多个行数相同的数据集，可以在相同的索引上分割数据集（这个功能非常有用，比如你的标签值是放在另一个<code>DataFrame</code>里的）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">train_set, test_set = train_test_split(housing, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure>
<p>目前为止，我们采用的都是纯随机的取样方法。当你的数据集很大时（尤其是和属性数相比），这通常可行；但如果数据集不大，就会有采样偏差的风险。当一个调查公司想要对 1000 个人进行调查，它们不是在电话亭里随机选 1000 个人出来。调查公司要保证这 1000 个人对人群整体有代表性。例如，美国人口的 51.3% 是女性，48.7% 是男性。所以在美国，严谨的调查需要保证样本也是这个比例：513 名女性，487 名男性。这称作分层采样（stratified sampling）：将人群分成均匀的子分组，称为分层，从每个分层去取合适数量的实例，以保证测试集对总人数有代表性。如果调查公司采用纯随机采样，会有 12% 的概率导致采样偏差：女性人数少于 49%，或多于 54%。不管发生那种情况，调查结果都会严重偏差。</p>
<p>假设专家告诉你，收入中位数是预测房价中位数非常重要的属性。你可能想要保证测试集可以代表整体数据集中的多种收入分类。因为收入中位数是一个连续的数值属性，你首先需要创建一个收入类别属性。再仔细地看一下收入中位数的柱状图（图 2-9）（译注：该图是对收入中位数处理过后的图）：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-6f5f192c61bd9806.png" alt=""></p>
<p>图 2-9 收入分类的柱状图</p>
<p>大多数的收入中位数的值聚集在 2-5（万美元），但是一些收入中位数会超过 6。数据集中的每个分层都要有足够的实例位于你的数据中，这点很重要。否则，对分层重要性的评估就会有偏差。这意味着，你不能有过多的分层，且每个分层都要足够大。后面的代码通过将收入中位数除以 1.5（以限制收入分类的数量），创建了一个收入类别属性，用<code>ceil</code>对值舍入（以产生离散的分类），然后将所有大于 5的分类归入到分类 5：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">housing[<span class="string">"income_cat"</span>] = np.ceil(housing[<span class="string">"median_income"</span>] / <span class="number">1.5</span>)</span><br><span class="line">housing[<span class="string">"income_cat"</span>].where(housing[<span class="string">"income_cat"</span>] &lt; <span class="number">5</span>, <span class="number">5.0</span>, inplace=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>现在，就可以根据收入分类，进行分层采样。你可以使用 Scikit-Learn 的<code>StratifiedShuffleSplit</code>类：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedShuffleSplit</span><br><span class="line"></span><br><span class="line">split = StratifiedShuffleSplit(n_splits=<span class="number">1</span>, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> train_index, test_index <span class="keyword">in</span> split.split(housing, housing[<span class="string">"income_cat"</span>]):</span><br><span class="line">    strat_train_set = housing.loc[train_index]</span><br><span class="line">    strat_test_set = housing.loc[test_index]</span><br></pre></td></tr></table></figure>
<p>检查下结果是否符合预期。你可以在完整的房产数据集中查看收入分类比例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing[<span class="string">"income_cat"</span>].value_counts() / len(housing)</span><br><span class="line"><span class="number">3.0</span>    <span class="number">0.350581</span></span><br><span class="line"><span class="number">2.0</span>    <span class="number">0.318847</span></span><br><span class="line"><span class="number">4.0</span>    <span class="number">0.176308</span></span><br><span class="line"><span class="number">5.0</span>    <span class="number">0.114438</span></span><br><span class="line"><span class="number">1.0</span>    <span class="number">0.039826</span></span><br><span class="line">Name: income_cat, dtype: float64</span><br></pre></td></tr></table></figure>
<p>使用相似的代码，还可以测量测试集中收入分类的比例。图 2-10 对比了总数据集、分层采样的测试集、纯随机采样测试集的收入分类比例。可以看到，分层采样测试集的收入分类比例与总数据集几乎相同，而随机采样数据集偏差严重。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-6aaaf5a4dfe511a5.png" alt=""></p>
<p>图 2-10 分层采样和纯随机采样的样本偏差比较</p>
<p>现在，你需要删除<code>income_cat</code>属性，使数据回到初始状态：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> set <span class="keyword">in</span> (strat_train_set, strat_test_set):</span><br><span class="line">    set.drop([<span class="string">"income_cat"</span>], axis=<span class="number">1</span>, inplace=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<p>我们用了大量时间来生成测试集的原因是：测试集通常被忽略，但实际是机器学习非常重要的一部分。还有，生成测试集过程中的许多思路对于后面的交叉验证讨论是非常有帮助的。接下来进入下一阶段：数据探索。</p>
<h2 id="数据探索和可视化、发现规律"><a href="#数据探索和可视化、发现规律" class="headerlink" title="数据探索和可视化、发现规律"></a>数据探索和可视化、发现规律</h2><p>目前为止，你只是快速查看了数据，对要处理的数据有了整体了解。现在的目标是更深的探索数据。</p>
<p>首先，保证你将测试集放在了一旁，只是研究训练集。另外，如果训练集非常大，你可能需要再采样一个探索集，保证操作方便快速。在我们的案例中，数据集很小，所以可以在全集上直接工作。创建一个副本，以免损伤训练集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">housing = strat_train_set.copy()</span><br></pre></td></tr></table></figure>
<h3 id="地理数据可视化"><a href="#地理数据可视化" class="headerlink" title="地理数据可视化"></a>地理数据可视化</h3><p>因为存在地理信息（纬度和经度），创建一个所有街区的散点图来数据可视化是一个不错的主意（图 2-11）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">housing.plot(kind=<span class="string">"scatter"</span>, x=<span class="string">"longitude"</span>, y=<span class="string">"latitude"</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-90fa1be435569d25.png" alt=""></p>
<p>图 2-11 数据的地理信息散点图</p>
<p>这张图看起来很像加州，但是看不出什么特别的规律。将<code>alpha</code>设为 0.1，可以更容易看出数据点的密度（图 2-12）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">housing.plot(kind=<span class="string">"scatter"</span>, x=<span class="string">"longitude"</span>, y=<span class="string">"latitude"</span>, alpha=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-cb9bec05a3d2ddca.png" alt=""></p>
<p>图 2-12 显示高密度区域的散点图</p>
<p>现在看起来好多了：可以非常清楚地看到高密度区域，湾区、洛杉矶和圣迭戈，以及中央谷，特别是从萨克拉门托和弗雷斯诺。</p>
<p>通常来讲，人类的大脑非常善于发现图片中的规律，但是需要调整可视化参数使规律显现出来。</p>
<p>现在来看房价（图 2-13）。每个圈的半径表示街区的人口（选项<code>s</code>），颜色代表价格（选项<code>c</code>）。我们用预先定义的名为<code>jet</code>的颜色图（选项<code>cmap</code>），它的范围是从蓝色（低价）到红色（高价）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">housing.plot(kind=<span class="string">"scatter"</span>, x=<span class="string">"longitude"</span>, y=<span class="string">"latitude"</span>, alpha=<span class="number">0.4</span>,</span><br><span class="line">    s=housing[<span class="string">"population"</span>]/<span class="number">100</span>, label=<span class="string">"population"</span>,</span><br><span class="line">    c=<span class="string">"median_house_value"</span>, cmap=plt.get_cmap(<span class="string">"jet"</span>), colorbar=<span class="keyword">True</span>,</span><br><span class="line">)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-017573305488b4da.png" alt=""></p>
<p>图 2-13 加州房价</p>
<p>这张图说明房价和位置（比如，靠海）和人口密度联系密切，这点你可能早就知道。可以使用聚类算法来检测主要的聚集，用一个新的特征值测量聚集中心的距离。尽管北加州海岸区域的房价不是非常高，但离大海距离属性也可能很有用，所以这不是用一个简单的规则就可以定义的问题。</p>
<h3 id="查找关联"><a href="#查找关联" class="headerlink" title="查找关联"></a>查找关联</h3><p>因为数据集并不是非常大，你可以很容易地使用<code>corr()</code>方法计算出每对属性间的标准相关系数（standard correlation coefficient，也称作皮尔逊相关系数）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">corr_matrix = housing.corr()</span><br></pre></td></tr></table></figure>
<p>现在来看下每个属性和房价中位数的关联度：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>corr_matrix[<span class="string">"median_house_value"</span>].sort_values(ascending=<span class="keyword">False</span>)</span><br><span class="line">median_house_value    <span class="number">1.000000</span></span><br><span class="line">median_income         <span class="number">0.687170</span></span><br><span class="line">total_rooms           <span class="number">0.135231</span></span><br><span class="line">housing_median_age    <span class="number">0.114220</span></span><br><span class="line">households            <span class="number">0.064702</span></span><br><span class="line">total_bedrooms        <span class="number">0.047865</span></span><br><span class="line">population           <span class="number">-0.026699</span></span><br><span class="line">longitude            <span class="number">-0.047279</span></span><br><span class="line">latitude             <span class="number">-0.142826</span></span><br><span class="line">Name: median_house_value, dtype: float64</span><br></pre></td></tr></table></figure>
<p>相关系数的范围是 -1 到 1。当接近 1 时，意味强正相关；例如，当收入中位数增加时，房价中位数也会增加。当相关系数接近 -1 时，意味强负相关；你可以看到，纬度和房价中位数有轻微的负相关性（即，越往北，房价越可能降低）。最后，相关系数接近 0，意味没有线性相关性。图 2-14 展示了相关系数在横轴和纵轴之间的不同图形。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-40836bf268955df7.png" alt=""></p>
<p>图 2-14 不同数据集的标准相关系数（来源：Wikipedia；公共领域图片）</p>
<blockquote>
<p>警告：相关系数只测量线性关系（如果<code>x</code>上升，<code>y</code>则上升或下降）。相关系数可能会完全忽略非线性关系（例如，如果<code>x</code>接近 0，则<code>y</code>值会变高）。在上面图片的最后一行中，他们的相关系数都接近于 0，尽管它们的轴并不独立：这些就是非线性关系的例子。另外，第二行的相关系数等于 1 或 -1；这和斜率没有任何关系。例如，你的身高（单位是英寸）与身高（单位是英尺或纳米）的相关系数就是 1。</p>
</blockquote>
<p>另一种检测属性间相关系数的方法是使用 Pandas 的<code>scatter_matrix</code>函数，它能画出每个数值属性对每个其它数值属性的图。因为现在共有 11 个数值属性，你可以得到<code>11 ** 2 = 121</code>张图，在一页上画不下，所以只关注几个和房价中位数最有可能相关的属性（图 2-15）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pandas.tools.plotting <span class="keyword">import</span> scatter_matrix</span><br><span class="line"></span><br><span class="line">attributes = [<span class="string">"median_house_value"</span>, <span class="string">"median_income"</span>, <span class="string">"total_rooms"</span>,</span><br><span class="line">              <span class="string">"housing_median_age"</span>]</span><br><span class="line">scatter_matrix(housing[attributes], figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-9260352458302ba0.png" alt=""></p>
<p>图 2-15 散点矩阵</p>
<p>如果 pandas 将每个变量对自己作图，主对角线（左上到右下）都会是直线图。所以 Pandas 展示的是每个属性的柱状图（也可以是其它的，请参考 Pandas 文档）。</p>
<p>最有希望用来预测房价中位数的属性是收入中位数，因此将这张图放大（图 2-16）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">housing.plot(kind=<span class="string">"scatter"</span>, x=<span class="string">"median_income"</span>,y=<span class="string">"median_house_value"</span>,</span><br><span class="line">             alpha=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://upload-images.jianshu.io/upload_images/7178691-2b0b2ac071f62636.png" alt=""></p>
<p>图 2-16 收入中位数 vs 房价中位数</p>
<p>这张图说明了几点。首先，相关性非常高；可以清晰地看到向上的趋势，并且数据点不是非常分散。第二，我们之前看到的最高价，清晰地呈现为一条位于 500000 美元的水平线。这张图也呈现了一些不是那么明显的直线：一条位于 450000 美元的直线，一条位于 350000 美元的直线，一条在 280000 美元的线，和一些更靠下的线。你可能希望去除对应的街区，以防止算法重复这些巧合。</p>
<h3 id="属性组合试验"><a href="#属性组合试验" class="headerlink" title="属性组合试验"></a>属性组合试验</h3><p>希望前面的一节能教给你一些探索数据、发现规律的方法。你发现了一些数据的巧合，需要在给算法提供数据之前，将其去除。你还发现了一些属性间有趣的关联，特别是目标属性。你还注意到一些属性具有长尾分布，因此你可能要将其进行转换（例如，计算其<code>log</code>对数）。当然，不同项目的处理方法各不相同，但大体思路是相似的。</p>
<p>给算法准备数据之前，你需要做的最后一件事是尝试多种属性组合。例如，如果你不知道某个街区有多少户，该街区的总房间数就没什么用。你真正需要的是每户有几个房间。相似的，总卧室数也不重要：你可能需要将其与房间数进行比较。每户的人口数也是一个有趣的属性组合。让我们来创建这些新的属性：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">housing[<span class="string">"rooms_per_household"</span>] = housing[<span class="string">"total_rooms"</span>]/housing[<span class="string">"households"</span>]</span><br><span class="line">housing[<span class="string">"bedrooms_per_room"</span>] = housing[<span class="string">"total_bedrooms"</span>]/housing[<span class="string">"total_rooms"</span>]</span><br><span class="line">housing[<span class="string">"population_per_household"</span>]=housing[<span class="string">"population"</span>]/housing[<span class="string">"households"</span>]</span><br></pre></td></tr></table></figure>
<p>现在，再来看相关矩阵：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>corr_matrix = housing.corr()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>corr_matrix[<span class="string">"median_house_value"</span>].sort_values(ascending=<span class="keyword">False</span>)</span><br><span class="line">median_house_value          <span class="number">1.000000</span></span><br><span class="line">median_income               <span class="number">0.687170</span></span><br><span class="line">rooms_per_household         <span class="number">0.199343</span></span><br><span class="line">total_rooms                 <span class="number">0.135231</span></span><br><span class="line">housing_median_age          <span class="number">0.114220</span></span><br><span class="line">households                  <span class="number">0.064702</span></span><br><span class="line">total_bedrooms              <span class="number">0.047865</span></span><br><span class="line">population_per_household   <span class="number">-0.021984</span></span><br><span class="line">population                 <span class="number">-0.026699</span></span><br><span class="line">longitude                  <span class="number">-0.047279</span></span><br><span class="line">latitude                   <span class="number">-0.142826</span></span><br><span class="line">bedrooms_per_room          <span class="number">-0.260070</span></span><br><span class="line">Name: median_house_value, dtype: float64</span><br></pre></td></tr></table></figure>
<p>看起来不错！与总房间数或卧室数相比，新的<code>bedrooms_per_room</code>属性与房价中位数的关联更强。显然，卧室数/总房间数的比例越低，房价就越高。每户的房间数也比街区的总房间数的更有信息，很明显，房屋越大，房价就越高。</p>
<p>这一步的数据探索不必非常完备，此处的目的是有一个正确的开始，快速发现规律，以得到一个合理的原型。但是这是一个交互过程：一旦你得到了一个原型，并运行起来，你就可以分析它的输出，进而发现更多的规律，然后再回到数据探索这步。</p>
<h2 id="为机器学习算法准备数据"><a href="#为机器学习算法准备数据" class="headerlink" title="为机器学习算法准备数据"></a>为机器学习算法准备数据</h2><p>现在来为机器学习算法准备数据。不要手工来做，你需要写一些函数，理由如下：</p>
<ul>
<li><p>函数可以让你在任何数据集上（比如，你下一次获取的是一个新的数据集）方便地进行重复数据转换。</p>
</li>
<li><p>你能慢慢建立一个转换函数库，可以在未来的项目中复用。</p>
</li>
<li><p>在将数据传给算法之前，你可以在实时系统中使用这些函数。</p>
</li>
<li><p>这可以让你方便地尝试多种数据转换，查看哪些转换方法结合起来效果最好。</p>
</li>
</ul>
<p>但是，还是先回到干净的训练集（通过再次复制<code>strat_train_set</code>），将预测量和标签分开，因为我们不想对预测量和目标值应用相同的转换（注意<code>drop()</code>创建了一份数据的备份，而不影响<code>strat_train_set</code>）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">housing = strat_train_set.drop(<span class="string">"median_house_value"</span>, axis=<span class="number">1</span>)</span><br><span class="line">housing_labels = strat_train_set[<span class="string">"median_house_value"</span>].copy()</span><br></pre></td></tr></table></figure>
<h3 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h3><p>大多机器学习算法不能处理缺失的特征，因此先创建一些函数来处理特征缺失的问题。前面，你应该注意到了属性<code>total_bedrooms</code>有一些缺失值。有三个解决选项：</p>
<ul>
<li><p>去掉对应的街区；</p>
</li>
<li><p>去掉整个属性；</p>
</li>
<li><p>进行赋值（0、平均值、中位数等等）。</p>
</li>
</ul>
<p>用<code>DataFrame</code>的<code>dropna()</code>，<code>drop()</code>，和<code>fillna()</code>方法，可以方便地实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">housing.dropna(subset=[<span class="string">"total_bedrooms"</span>])    <span class="comment"># 选项1</span></span><br><span class="line">housing.drop(<span class="string">"total_bedrooms"</span>, axis=<span class="number">1</span>)       <span class="comment"># 选项2</span></span><br><span class="line">median = housing[<span class="string">"total_bedrooms"</span>].median()</span><br><span class="line">housing[<span class="string">"total_bedrooms"</span>].fillna(median)     <span class="comment"># 选项3</span></span><br></pre></td></tr></table></figure>
<p>如果选择选项 3，你需要计算训练集的中位数，用中位数填充训练集的缺失值，不要忘记保存该中位数。后面用测试集评估系统时，需要替换测试集中的缺失值，也可以用来实时替换新数据中的缺失值。</p>
<p>Scikit-Learn 提供了一个方便的类来处理缺失值：<code>Imputer</code>。下面是其使用方法：首先，需要创建一个<code>Imputer</code>实例，指定用某属性的中位数来替换该属性所有的缺失值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Imputer</span><br><span class="line"></span><br><span class="line">imputer = Imputer(strategy=<span class="string">"median"</span>)</span><br></pre></td></tr></table></figure>
<p>因为只有数值属性才能算出中位数，我们需要创建一份不包括文本属性<code>ocean_proximity</code>的数据副本：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">housing_num = housing.drop(<span class="string">"ocean_proximity"</span>, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>现在，就可以用<code>fit()</code>方法将<code>imputer</code>实例拟合到训练数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">imputer.fit(housing_num)</span><br></pre></td></tr></table></figure>
<p><code>imputer</code>计算出了每个属性的中位数，并将结果保存在了实例变量<code>statistics_</code>中。虽然此时只有属性<code>total_bedrooms</code>存在缺失值，但我们不能确定在以后的新的数据中会不会有其他属性也存在缺失值，所以安全的做法是将<code>imputer</code>应用到每个数值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>imputer.statistics_</span><br><span class="line">array([ <span class="number">-118.51</span> , <span class="number">34.26</span> , <span class="number">29.</span> , <span class="number">2119.</span> , <span class="number">433.</span> , <span class="number">1164.</span> , <span class="number">408.</span> , <span class="number">3.5414</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_num.median().values</span><br><span class="line">array([ <span class="number">-118.51</span> , <span class="number">34.26</span> , <span class="number">29.</span> , <span class="number">2119.</span> , <span class="number">433.</span> , <span class="number">1164.</span> , <span class="number">408.</span> , <span class="number">3.5414</span>])</span><br></pre></td></tr></table></figure>
<p>现在，你就可以使用这个“训练过的”<code>imputer</code>来对训练集进行转换，将缺失值替换为中位数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X = imputer.transform(housing_num)</span><br></pre></td></tr></table></figure>
<p>结果是一个包含转换后特征的普通的 Numpy 数组。如果你想将其放回到 Pandas<code>DataFrame</code>中，也很简单：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">housing_tr = pd.DataFrame(X, columns=housing_num.columns)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Scikit-Learn 设计</p>
<p>Scikit-Learn 设计的 API 设计的非常好。它的主要设计原则是：</p>
<ul>
<li><p>一致性：所有对象的接口一致且简单：</p>
<ul>
<li>估计器（estimator）。任何可以基于数据集对一些参数进行估计的对象都被称为估计器（比如，<code>imputer</code>就是个估计器）。估计本身是通过<code>fit()</code>方法，只需要一个数据集作为参数（对于监督学习算法，需要两个数据集；第二个数据集包含标签）。任何其它用来指导估计过程的参数都被当做超参数（比如<code>imputer</code>的<code>strategy</code>），并且超参数要被设置成实例变量（通常通过构造器参数设置）。</li>
<li>转换器（transformer）。一些估计器（比如<code>imputer</code>）也可以转换数据集，这些估计器被称为转换器。API也是相当简单：转换是通过<code>transform()</code>方法，被转换的数据集作为参数。返回的是经过转换的数据集。转换过程依赖学习到的参数，比如<code>imputer</code>的例子。所有的转换都有一个便捷的方法<code>fit_transform()</code>，等同于调用<code>fit()</code>再<code>transform()</code>（但有时<code>fit_transform()</code>经过优化，运行的更快）。</li>
<li>预测器（predictor）。最后，一些估计器可以根据给出的数据集做预测，这些估计器称为预测器。例如，上一章的<code>LinearRegression</code>模型就是一个预测器：它根据一个国家的人均 GDP 预测生活满意度。预测器有一个<code>predict()</code>方法，可以用新实例的数据集做出相应的预测。预测器还有一个<code>score()</code>方法，可以根据测试集（和相应的标签，如果是监督学习算法的话）对预测进行衡器。</li>
</ul>
</li>
<li><p>可检验。所有估计器的超参数都可以通过实例的public变量直接访问（比如，<code>imputer.strategy</code>），并且所有估计器学习到的参数也可以通过在实例变量名后加下划线来访问（比如，<code>imputer.statistics_</code>）。</p>
</li>
<li><p>类不可扩散。数据集被表示成 NumPy 数组或 SciPy 稀疏矩阵，而不是自制的类。超参数只是普通的 Python 字符串或数字。</p>
</li>
<li><p>可组合。尽可能使用现存的模块。例如，用任意的转换器序列加上一个估计器，就可以做成一个流水线，后面会看到例子。</p>
</li>
<li><p>合理的默认值。Scikit-Learn 给大多数参数提供了合理的默认值，很容易就能创建一个系统。</p>
</li>
</ul>
</blockquote>
<h3 id="处理文本和类别属性"><a href="#处理文本和类别属性" class="headerlink" title="处理文本和类别属性"></a>处理文本和类别属性</h3><p>前面，我们丢弃了类别属性<code>ocean_proximity</code>，因为它是一个文本属性，不能计算出中位数。大多数机器学习算法跟喜欢和数字打交道，所以让我们把这些文本标签转换为数字。</p>
<p>Scikit-Learn 为这个任务提供了一个转换器<code>LabelEncoder</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>encoder = LabelEncoder()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_cat = housing[<span class="string">"ocean_proximity"</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_cat_encoded = encoder.fit_transform(housing_cat)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_cat_encoded</span><br><span class="line">array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>, ..., <span class="number">1</span>, <span class="number">0</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure>
<blockquote>
<p>译注:</p>
<p>在原书中使用<code>LabelEncoder</code>转换器来转换文本特征列的方式是错误的，该转换器只能用来转换标签（正如其名）。在这里使用<code>LabelEncoder</code>没有出错的原因是该数据只有一列文本特征值，在有多个文本特征列的时候就会出错。应使用<code>factorize()</code>方法来进行操作：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; housing_cat_encoded, housing_categories = housing_cat.factorize()</span><br><span class="line">&gt; housing_cat_encoded[:<span class="number">10</span>]</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>好了一些，现在就可以在任何 ML 算法里用这个数值数据了。你可以查看映射表，编码器是通过属性<code>classes_</code>来学习的（<code>&lt;1H OCEAN</code>被映射为 0，<code>INLAND</code>被映射为 1，等等）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(encoder.classes_)</span><br><span class="line">[<span class="string">'&lt;1H OCEAN'</span> <span class="string">'INLAND'</span> <span class="string">'ISLAND'</span> <span class="string">'NEAR BAY'</span> <span class="string">'NEAR OCEAN'</span>]</span><br></pre></td></tr></table></figure>
<p>这种做法的问题是，ML 算法会认为两个临近的值比两个疏远的值要更相似。显然这样不对（比如，分类 0 和 4 比 0 和 1 更相似）。要解决这个问题，一个常见的方法是给每个分类创建一个二元属性：当分类是<code>&lt;1H OCEAN</code>，该属性为 1（否则为 0），当分类是<code>INLAND</code>，另一个属性等于 1（否则为 0），以此类推。这称作独热编码（One-Hot Encoding），因为只有一个属性会等于 1（热），其余会是 0（冷）。</p>
<p>Scikit-Learn 提供了一个编码器<code>OneHotEncoder</code>，用于将整数分类值转变为独热向量。注意<code>fit_transform()</code>用于 2D 数组，而<code>housing_cat_encoded</code>是一个 1D 数组，所以需要将其变形：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>encoder = OneHotEncoder()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_cat_1hot = encoder.fit_transform(housing_cat_encoded.reshape(<span class="number">-1</span>,<span class="number">1</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_cat_1hot</span><br><span class="line">&lt;<span class="number">16513</span>x5 sparse matrix of type <span class="string">'&lt;class '</span>numpy.float64<span class="string">'&gt;'</span></span><br><span class="line">    <span class="keyword">with</span> <span class="number">16513</span> stored elements <span class="keyword">in</span> Compressed Sparse Row format&gt;</span><br></pre></td></tr></table></figure>
<p>注意输出结果是一个 SciPy 稀疏矩阵，而不是 NumPy 数组。当类别属性有数千个分类时，这样非常有用。经过独热编码，我们得到了一个有数千列的矩阵，这个矩阵每行只有一个 1，其余都是 0。使用大量内存来存储这些 0 非常浪费，所以稀疏矩阵只存储非零元素的位置。你可以像一个 2D 数据那样进行使用，但是如果你真的想将其转变成一个（密集的）NumPy 数组，只需调用<code>toarray()</code>方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_cat_1hot.toarray()</span><br><span class="line">array([[ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>],</span><br><span class="line">       ...,</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>],</span><br><span class="line">       [ <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">0.</span>]])</span><br></pre></td></tr></table></figure>
<p>使用类<code>LabelBinarizer</code>，我们可以用一步执行这两个转换（从文本分类到整数分类，再从整数分类到独热向量）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelBinarizer</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>encoder = LabelBinarizer()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_cat_1hot = encoder.fit_transform(housing_cat)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_cat_1hot</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">       ...,</span><br><span class="line">       [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]])</span><br></pre></td></tr></table></figure>
<p>注意默认返回的结果是一个密集 NumPy 数组。向构造器<code>LabelBinarizer</code>传递<code>sparse_output=True</code>，就可以得到一个稀疏矩阵。</p>
<blockquote>
<p>译注:</p>
<p>在原书中使用<code>LabelBinarizer</code>的方式也是错误的，该类也应用于标签列的转换。正确做法是使用sklearn即将提供的<code>CategoricalEncoder</code>类。如果在你阅读此文时sklearn中尚未提供此类，用如下方式代替：（来自<a href="https://github.com/scikit-learn/scikit-learn/pull/9151" target="_blank" rel="noopener">Pull Request #9151）</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br></pre></td><td class="code"><pre><span class="line">&gt; <span class="comment"># Definition of the CategoricalEncoder class, copied from PR #9151.</span></span><br><span class="line">&gt; <span class="comment"># Just run this cell, or copy it to your code, do not try to understand it (yet).</span></span><br><span class="line">&gt; </span><br><span class="line">&gt; <span class="keyword">from</span> sklearn.base <span class="keyword">import</span> BaseEstimator, TransformerMixin</span><br><span class="line">&gt; <span class="keyword">from</span> sklearn.utils <span class="keyword">import</span> check_array</span><br><span class="line">&gt; <span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line">&gt; <span class="keyword">from</span> scipy <span class="keyword">import</span> sparse</span><br><span class="line">&gt; </span><br><span class="line">&gt; <span class="class"><span class="keyword">class</span> <span class="title">CategoricalEncoder</span><span class="params">(BaseEstimator, TransformerMixin)</span>:</span></span><br><span class="line">&gt;     <span class="string">"""Encode categorical features as a numeric array.</span></span><br><span class="line"><span class="string">&gt;     The input to this transformer should be a matrix of integers or strings,</span></span><br><span class="line"><span class="string">&gt;     denoting the values taken on by categorical (discrete) features.</span></span><br><span class="line"><span class="string">&gt;     The features can be encoded using a one-hot aka one-of-K scheme</span></span><br><span class="line"><span class="string">&gt;     (``encoding='onehot'``, the default) or converted to ordinal integers</span></span><br><span class="line"><span class="string">&gt;     (``encoding='ordinal'``).</span></span><br><span class="line"><span class="string">&gt;     This encoding is needed for feeding categorical data to many scikit-learn</span></span><br><span class="line"><span class="string">&gt;     estimators, notably linear models and SVMs with the standard kernels.</span></span><br><span class="line"><span class="string">&gt;     Read more in the :ref:`User Guide &lt;preprocessing_categorical_features&gt;`.</span></span><br><span class="line"><span class="string">&gt;     Parameters</span></span><br><span class="line"><span class="string">&gt;     ----------</span></span><br><span class="line"><span class="string">&gt;     encoding : str, 'onehot', 'onehot-dense' or 'ordinal'</span></span><br><span class="line"><span class="string">&gt;         The type of encoding to use (default is 'onehot'):</span></span><br><span class="line"><span class="string">&gt;         - 'onehot': encode the features using a one-hot aka one-of-K scheme</span></span><br><span class="line"><span class="string">&gt;           (or also called 'dummy' encoding). This creates a binary column for</span></span><br><span class="line"><span class="string">&gt;           each category and returns a sparse matrix.</span></span><br><span class="line"><span class="string">&gt;         - 'onehot-dense': the same as 'onehot' but returns a dense array</span></span><br><span class="line"><span class="string">&gt;           instead of a sparse matrix.</span></span><br><span class="line"><span class="string">&gt;         - 'ordinal': encode the features as ordinal integers. This results in</span></span><br><span class="line"><span class="string">&gt;           a single column of integers (0 to n_categories - 1) per feature.</span></span><br><span class="line"><span class="string">&gt;     categories : 'auto' or a list of lists/arrays of values.</span></span><br><span class="line"><span class="string">&gt;         Categories (unique values) per feature:</span></span><br><span class="line"><span class="string">&gt;         - 'auto' : Determine categories automatically from the training data.</span></span><br><span class="line"><span class="string">&gt;         - list : ``categories[i]`` holds the categories expected in the ith</span></span><br><span class="line"><span class="string">&gt;           column. The passed categories are sorted before encoding the data</span></span><br><span class="line"><span class="string">&gt;           (used categories can be found in the ``categories_`` attribute).</span></span><br><span class="line"><span class="string">&gt;     dtype : number type, default np.float64</span></span><br><span class="line"><span class="string">&gt;         Desired dtype of output.</span></span><br><span class="line"><span class="string">&gt;     handle_unknown : 'error' (default) or 'ignore'</span></span><br><span class="line"><span class="string">&gt;         Whether to raise an error or ignore if a unknown categorical feature is</span></span><br><span class="line"><span class="string">&gt;         present during transform (default is to raise). When this is parameter</span></span><br><span class="line"><span class="string">&gt;         is set to 'ignore' and an unknown category is encountered during</span></span><br><span class="line"><span class="string">&gt;         transform, the resulting one-hot encoded columns for this feature</span></span><br><span class="line"><span class="string">&gt;         will be all zeros.</span></span><br><span class="line"><span class="string">&gt;         Ignoring unknown categories is not supported for</span></span><br><span class="line"><span class="string">&gt;         ``encoding='ordinal'``.</span></span><br><span class="line"><span class="string">&gt;     Attributes</span></span><br><span class="line"><span class="string">&gt;     ----------</span></span><br><span class="line"><span class="string">&gt;     categories_ : list of arrays</span></span><br><span class="line"><span class="string">&gt;         The categories of each feature determined during fitting. When</span></span><br><span class="line"><span class="string">&gt;         categories were specified manually, this holds the sorted categories</span></span><br><span class="line"><span class="string">&gt;         (in order corresponding with output of `transform`).</span></span><br><span class="line"><span class="string">&gt;     Examples</span></span><br><span class="line"><span class="string">&gt;     --------</span></span><br><span class="line"><span class="string">&gt;     Given a dataset with three features and two samples, we let the encoder</span></span><br><span class="line"><span class="string">&gt;     find the maximum value per feature and transform the data to a binary</span></span><br><span class="line"><span class="string">&gt;     one-hot encoding.</span></span><br><span class="line"><span class="string">&gt;     &gt;&gt;&gt; from sklearn.preprocessing import CategoricalEncoder</span></span><br><span class="line"><span class="string">&gt;     &gt;&gt;&gt; enc = CategoricalEncoder(handle_unknown='ignore')</span></span><br><span class="line"><span class="string">&gt;     &gt;&gt;&gt; enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]])</span></span><br><span class="line"><span class="string">&gt;     ... # doctest: +ELLIPSIS</span></span><br><span class="line"><span class="string">&gt;     CategoricalEncoder(categories='auto', dtype=&lt;... 'numpy.float64'&gt;,</span></span><br><span class="line"><span class="string">&gt;               encoding='onehot', handle_unknown='ignore')</span></span><br><span class="line"><span class="string">&gt;     &gt;&gt;&gt; enc.transform([[0, 1, 1], [1, 0, 4]]).toarray()</span></span><br><span class="line"><span class="string">&gt;     array([[ 1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.],</span></span><br><span class="line"><span class="string">&gt;            [ 0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]])</span></span><br><span class="line"><span class="string">&gt;     See also</span></span><br><span class="line"><span class="string">&gt;     --------</span></span><br><span class="line"><span class="string">&gt;     sklearn.preprocessing.OneHotEncoder : performs a one-hot encoding of</span></span><br><span class="line"><span class="string">&gt;       integer ordinal features. The ``OneHotEncoder assumes`` that input</span></span><br><span class="line"><span class="string">&gt;       features take on values in the range ``[0, max(feature)]`` instead of</span></span><br><span class="line"><span class="string">&gt;       using the unique values.</span></span><br><span class="line"><span class="string">&gt;     sklearn.feature_extraction.DictVectorizer : performs a one-hot encoding of</span></span><br><span class="line"><span class="string">&gt;       dictionary items (also handles string-valued features).</span></span><br><span class="line"><span class="string">&gt;     sklearn.feature_extraction.FeatureHasher : performs an approximate one-hot</span></span><br><span class="line"><span class="string">&gt;       encoding of dictionary items or strings.</span></span><br><span class="line"><span class="string">&gt;     """</span></span><br><span class="line">&gt; </span><br><span class="line">&gt;     <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, encoding=<span class="string">'onehot'</span>, categories=<span class="string">'auto'</span>, dtype=np.float64,</span></span></span><br><span class="line"><span class="function"><span class="params">&gt;                  handle_unknown=<span class="string">'error'</span>)</span>:</span></span><br><span class="line">&gt;         self.encoding = encoding</span><br><span class="line">&gt;         self.categories = categories</span><br><span class="line">&gt;         self.dtype = dtype</span><br><span class="line">&gt;         self.handle_unknown = handle_unknown</span><br><span class="line">&gt; </span><br><span class="line">&gt;     <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y=None)</span>:</span></span><br><span class="line">&gt;         <span class="string">"""Fit the CategoricalEncoder to X.</span></span><br><span class="line"><span class="string">&gt;         Parameters</span></span><br><span class="line"><span class="string">&gt;         ----------</span></span><br><span class="line"><span class="string">&gt;         X : array-like, shape [n_samples, n_feature]</span></span><br><span class="line"><span class="string">&gt;             The data to determine the categories of each feature.</span></span><br><span class="line"><span class="string">&gt;         Returns</span></span><br><span class="line"><span class="string">&gt;         -------</span></span><br><span class="line"><span class="string">&gt;         self</span></span><br><span class="line"><span class="string">&gt;         """</span></span><br><span class="line">&gt; </span><br><span class="line">&gt;         <span class="keyword">if</span> self.encoding <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'onehot'</span>, <span class="string">'onehot-dense'</span>, <span class="string">'ordinal'</span>]:</span><br><span class="line">&gt;             template = (<span class="string">"encoding should be either 'onehot', 'onehot-dense' "</span></span><br><span class="line">&gt;                         <span class="string">"or 'ordinal', got %s"</span>)</span><br><span class="line">&gt;             <span class="keyword">raise</span> ValueError(template % self.handle_unknown)</span><br><span class="line">&gt; </span><br><span class="line">&gt;         <span class="keyword">if</span> self.handle_unknown <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">'error'</span>, <span class="string">'ignore'</span>]:</span><br><span class="line">&gt;             template = (<span class="string">"handle_unknown should be either 'error' or "</span></span><br><span class="line">&gt;                         <span class="string">"'ignore', got %s"</span>)</span><br><span class="line">&gt;             <span class="keyword">raise</span> ValueError(template % self.handle_unknown)</span><br><span class="line">&gt; </span><br><span class="line">&gt;         <span class="keyword">if</span> self.encoding == <span class="string">'ordinal'</span> <span class="keyword">and</span> self.handle_unknown == <span class="string">'ignore'</span>:</span><br><span class="line">&gt;             <span class="keyword">raise</span> ValueError(<span class="string">"handle_unknown='ignore' is not supported for"</span></span><br><span class="line">&gt;                              <span class="string">" encoding='ordinal'"</span>)</span><br><span class="line">&gt; </span><br><span class="line">&gt;         X = check_array(X, dtype=np.object, accept_sparse=<span class="string">'csc'</span>, copy=<span class="keyword">True</span>)</span><br><span class="line">&gt;         n_samples, n_features = X.shape</span><br><span class="line">&gt; </span><br><span class="line">&gt;         self._label_encoders_ = [LabelEncoder() <span class="keyword">for</span> _ <span class="keyword">in</span> range(n_features)]</span><br><span class="line">&gt; </span><br><span class="line">&gt;         <span class="keyword">for</span> i <span class="keyword">in</span> range(n_features):</span><br><span class="line">&gt;             le = self._label_encoders_[i]</span><br><span class="line">&gt;             Xi = X[:, i]</span><br><span class="line">&gt;             <span class="keyword">if</span> self.categories == <span class="string">'auto'</span>:</span><br><span class="line">&gt;                 le.fit(Xi)</span><br><span class="line">&gt;             <span class="keyword">else</span>:</span><br><span class="line">&gt;                 valid_mask = np.in1d(Xi, self.categories[i])</span><br><span class="line">&gt;                 <span class="keyword">if</span> <span class="keyword">not</span> np.all(valid_mask):</span><br><span class="line">&gt;                     <span class="keyword">if</span> self.handle_unknown == <span class="string">'error'</span>:</span><br><span class="line">&gt;                         diff = np.unique(Xi[~valid_mask])</span><br><span class="line">&gt;                         msg = (<span class="string">"Found unknown categories &#123;0&#125; in column &#123;1&#125;"</span></span><br><span class="line">&gt;                                <span class="string">" during fit"</span>.format(diff, i))</span><br><span class="line">&gt;                         <span class="keyword">raise</span> ValueError(msg)</span><br><span class="line">&gt;                 le.classes_ = np.array(np.sort(self.categories[i]))</span><br><span class="line">&gt; </span><br><span class="line">&gt;         self.categories_ = [le.classes_ <span class="keyword">for</span> le <span class="keyword">in</span> self._label_encoders_]</span><br><span class="line">&gt; </span><br><span class="line">&gt;         <span class="keyword">return</span> self</span><br><span class="line">&gt; </span><br><span class="line">&gt;     <span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(self, X)</span>:</span></span><br><span class="line">&gt;         <span class="string">"""Transform X using one-hot encoding.</span></span><br><span class="line"><span class="string">&gt;         Parameters</span></span><br><span class="line"><span class="string">&gt;         ----------</span></span><br><span class="line"><span class="string">&gt;         X : array-like, shape [n_samples, n_features]</span></span><br><span class="line"><span class="string">&gt;             The data to encode.</span></span><br><span class="line"><span class="string">&gt;         Returns</span></span><br><span class="line"><span class="string">&gt;         -------</span></span><br><span class="line"><span class="string">&gt;         X_out : sparse matrix or a 2-d array</span></span><br><span class="line"><span class="string">&gt;             Transformed input.</span></span><br><span class="line"><span class="string">&gt;         """</span></span><br><span class="line">&gt;         X = check_array(X, accept_sparse=<span class="string">'csc'</span>, dtype=np.object, copy=<span class="keyword">True</span>)</span><br><span class="line">&gt;         n_samples, n_features = X.shape</span><br><span class="line">&gt;         X_int = np.zeros_like(X, dtype=np.int)</span><br><span class="line">&gt;         X_mask = np.ones_like(X, dtype=np.bool)</span><br><span class="line">&gt; </span><br><span class="line">&gt;         <span class="keyword">for</span> i <span class="keyword">in</span> range(n_features):</span><br><span class="line">&gt;             valid_mask = np.in1d(X[:, i], self.categories_[i])</span><br><span class="line">&gt; </span><br><span class="line">&gt;             <span class="keyword">if</span> <span class="keyword">not</span> np.all(valid_mask):</span><br><span class="line">&gt;                 <span class="keyword">if</span> self.handle_unknown == <span class="string">'error'</span>:</span><br><span class="line">&gt;                     diff = np.unique(X[~valid_mask, i])</span><br><span class="line">&gt;                     msg = (<span class="string">"Found unknown categories &#123;0&#125; in column &#123;1&#125;"</span></span><br><span class="line">&gt;                            <span class="string">" during transform"</span>.format(diff, i))</span><br><span class="line">&gt;                     <span class="keyword">raise</span> ValueError(msg)</span><br><span class="line">&gt;                 <span class="keyword">else</span>:</span><br><span class="line">&gt;                     <span class="comment"># Set the problematic rows to an acceptable value and</span></span><br><span class="line">&gt;                     <span class="comment"># continue `The rows are marked `X_mask` and will be</span></span><br><span class="line">&gt;                     <span class="comment"># removed later.</span></span><br><span class="line">&gt;                     X_mask[:, i] = valid_mask</span><br><span class="line">&gt;                     X[:, i][~valid_mask] = self.categories_[i][<span class="number">0</span>]</span><br><span class="line">&gt;             X_int[:, i] = self._label_encoders_[i].transform(X[:, i])</span><br><span class="line">&gt; </span><br><span class="line">&gt;         <span class="keyword">if</span> self.encoding == <span class="string">'ordinal'</span>:</span><br><span class="line">&gt;             <span class="keyword">return</span> X_int.astype(self.dtype, copy=<span class="keyword">False</span>)</span><br><span class="line">&gt; </span><br><span class="line">&gt;         mask = X_mask.ravel()</span><br><span class="line">&gt;         n_values = [cats.shape[<span class="number">0</span>] <span class="keyword">for</span> cats <span class="keyword">in</span> self.categories_]</span><br><span class="line">&gt;         n_values = np.array([<span class="number">0</span>] + n_values)</span><br><span class="line">&gt;         indices = np.cumsum(n_values)</span><br><span class="line">&gt; </span><br><span class="line">&gt;         column_indices = (X_int + indices[:<span class="number">-1</span>]).ravel()[mask]</span><br><span class="line">&gt;         row_indices = np.repeat(np.arange(n_samples, dtype=np.int32),</span><br><span class="line">&gt;                                 n_features)[mask]</span><br><span class="line">&gt;         data = np.ones(n_samples * n_features)[mask]</span><br><span class="line">&gt; </span><br><span class="line">&gt;         out = sparse.csc_matrix((data, (row_indices, column_indices)),</span><br><span class="line">&gt;                                 shape=(n_samples, indices[<span class="number">-1</span>]),</span><br><span class="line">&gt;                                 dtype=self.dtype).tocsr()</span><br><span class="line">&gt;         <span class="keyword">if</span> self.encoding == <span class="string">'onehot-dense'</span>:</span><br><span class="line">&gt;             <span class="keyword">return</span> out.toarray()</span><br><span class="line">&gt;         <span class="keyword">else</span>:</span><br><span class="line">&gt;             <span class="keyword">return</span> out</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<blockquote>
<p>转换方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt; <span class="comment">#from sklearn.preprocessing import CategoricalEncoder # in future versions of Scikit-Learn</span></span><br><span class="line">&gt; </span><br><span class="line">&gt; cat_encoder = CategoricalEncoder()</span><br><span class="line">&gt; housing_cat_reshaped = housing_cat.values.reshape(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line">&gt; housing_cat_1hot = cat_encoder.fit_transform(housing_cat_reshaped)</span><br><span class="line">&gt; housing_cat_1hot</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="自定义转换器"><a href="#自定义转换器" class="headerlink" title="自定义转换器"></a>自定义转换器</h3><p>尽管 Scikit-Learn 提供了许多有用的转换器，你还是需要自己动手写转换器执行任务，比如自定义的清理操作，或属性组合。你需要让自制的转换器与 Scikit-Learn 组件（比如流水线）无缝衔接工作，因为 Scikit-Learn 是依赖鸭子类型的（而不是继承），你所需要做的是创建一个类并执行三个方法：<code>fit()</code>（返回<code>self</code>），<code>transform()</code>，和<code>fit_transform()</code>。通过添加<code>TransformerMixin</code>作为基类，可以很容易地得到最后一个。另外，如果你添加<code>BaseEstimator</code>作为基类（且构造器中避免使用<code>*args</code>和<code>**kargs</code>），你就能得到两个额外的方法（<code>get_params()</code>和<code>set_params()</code>），二者可以方便地进行超参数自动微调。例如，一个小转换器类添加了上面讨论的属性：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> BaseEstimator, TransformerMixin</span><br><span class="line">rooms_ix, bedrooms_ix, population_ix, household_ix = <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CombinedAttributesAdder</span><span class="params">(BaseEstimator, TransformerMixin)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, add_bedrooms_per_room = True)</span>:</span> <span class="comment"># no *args or **kargs</span></span><br><span class="line">        self.add_bedrooms_per_room = add_bedrooms_per_room</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y=None)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self  <span class="comment"># nothing else to do</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(self, X, y=None)</span>:</span></span><br><span class="line">        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]</span><br><span class="line">        population_per_household = X[:, population_ix] / X[:, household_ix]</span><br><span class="line">        <span class="keyword">if</span> self.add_bedrooms_per_room:</span><br><span class="line">            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]</span><br><span class="line">            <span class="keyword">return</span> np.c_[X, rooms_per_household, population_per_household,</span><br><span class="line">                         bedrooms_per_room]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> np.c_[X, rooms_per_household, population_per_household]</span><br><span class="line"></span><br><span class="line">attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=<span class="keyword">False</span>)</span><br><span class="line">housing_extra_attribs = attr_adder.transform(housing.values)</span><br></pre></td></tr></table></figure>
<p>在这个例子中，转换器有一个超参数<code>add_bedrooms_per_room</code>，默认设为<code>True</code>（提供一个合理的默认值很有帮助）。这个超参数可以让你方便地发现添加了这个属性是否对机器学习算法有帮助。更一般地，你可以为每个不能完全确保的数据准备步骤添加一个超参数。数据准备步骤越自动化，可以自动化的操作组合就越多，越容易发现更好用的组合（并能节省大量时间）。</p>
<h3 id="特征缩放"><a href="#特征缩放" class="headerlink" title="特征缩放"></a>特征缩放</h3><p>数据要做的最重要的转换之一是特征缩放。除了个别情况，当输入的数值属性量度不同时，机器学习算法的性能都不会好。这个规律也适用于房产数据：总房间数分布范围是 6 到 39320，而收入中位数只分布在 0 到 15。注意通常情况下我们不需要对目标值进行缩放。</p>
<p>有两种常见的方法可以让所有的属性有相同的量度：线性函数归一化（Min-Max scaling）和标准化（standardization）。</p>
<p>线性函数归一化（许多人称其为归一化（normalization））很简单：值被转变、重新缩放，直到范围变成 0 到 1。我们通过减去最小值，然后再除以最大值与最小值的差值，来进行归一化。Scikit-Learn 提供了一个转换器<code>MinMaxScaler</code>来实现这个功能。它有一个超参数<code>feature_range</code>，可以让你改变范围，如果不希望范围是 0 到 1。</p>
<p>标准化就很不同：首先减去平均值（所以标准化值的平均值总是 0），然后除以方差，使得到的分布具有单位方差。与归一化不同，标准化不会限定值到某个特定的范围，这对某些算法可能构成问题（比如，神经网络常需要输入值得范围是 0 到 1）。但是，标准化受到异常值的影响很小。例如，假设一个街区的收入中位数由于某种错误变成了100，归一化会将其它范围是 0 到 15 的值变为 0-0.15，但是标准化不会受什么影响。Scikit-Learn 提供了一个转换器<code>StandardScaler</code>来进行标准化。</p>
<blockquote>
<p>警告：与所有的转换一样，缩放器只能向训练集拟合，而不是向完整的数据集（包括测试集）。只有这样，你才能用缩放器转换训练集和测试集（和新数据）。</p>
</blockquote>
<h3 id="转换流水线"><a href="#转换流水线" class="headerlink" title="转换流水线"></a>转换流水线</h3><p>你已经看到，存在许多数据转换步骤，需要按一定的顺序执行。幸运的是，Scikit-Learn 提供了类<code>Pipeline</code>，来进行这一系列的转换。下面是一个数值属性的小流水线：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line">num_pipeline = Pipeline([</span><br><span class="line">        (<span class="string">'imputer'</span>, Imputer(strategy=<span class="string">"median"</span>)),</span><br><span class="line">        (<span class="string">'attribs_adder'</span>, CombinedAttributesAdder()),</span><br><span class="line">        (<span class="string">'std_scaler'</span>, StandardScaler()),</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">housing_num_tr = num_pipeline.fit_transform(housing_num)</span><br></pre></td></tr></table></figure>
<p><code>Pipeline</code>构造器需要一个定义步骤顺序的名字/估计器对的列表。除了最后一个估计器，其余都要是转换器（即，它们都要有<code>fit_transform()</code>方法）。名字可以随意起。</p>
<p>当你调用流水线的<code>fit()</code>方法，就会对所有转换器顺序调用<code>fit_transform()</code>方法，将每次调用的输出作为参数传递给下一个调用，一直到最后一个估计器，它只执行<code>fit()</code>方法。</p>
<p>流水线暴露相同的方法作为最终的估计器。在这个例子中，最后的估计器是一个<code>StandardScaler</code>，它是一个转换器，因此这个流水线有一个<code>transform()</code>方法，可以顺序对数据做所有转换（它还有一个<code>fit_transform</code>方法可以使用，就不必先调用<code>fit()</code>再进行<code>transform()</code>）。</p>
<p>你现在就有了一个对数值的流水线，你还需要对分类值应用<code>LabelBinarizer</code>：如何将这些转换写成一个流水线呢？Scikit-Learn 提供了一个类<code>FeatureUnion</code>实现这个功能。你给它一列转换器（可以是所有的转换器），当调用它的<code>transform()</code>方法，每个转换器的<code>transform()</code>会被并行执行，等待输出，然后将输出合并起来，并返回结果（当然，调用它的<code>fit()</code>方法就会调用每个转换器的<code>fit()</code>）。一个完整的处理数值和类别属性的流水线如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> FeatureUnion</span><br><span class="line"></span><br><span class="line">num_attribs = list(housing_num)</span><br><span class="line">cat_attribs = [<span class="string">"ocean_proximity"</span>]</span><br><span class="line"></span><br><span class="line">num_pipeline = Pipeline([</span><br><span class="line">        (<span class="string">'selector'</span>, DataFrameSelector(num_attribs)),</span><br><span class="line">        (<span class="string">'imputer'</span>, Imputer(strategy=<span class="string">"median"</span>)),</span><br><span class="line">        (<span class="string">'attribs_adder'</span>, CombinedAttributesAdder()),</span><br><span class="line">        (<span class="string">'std_scaler'</span>, StandardScaler()),</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">cat_pipeline = Pipeline([</span><br><span class="line">        (<span class="string">'selector'</span>, DataFrameSelector(cat_attribs)),</span><br><span class="line">        (<span class="string">'label_binarizer'</span>, LabelBinarizer()),</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">full_pipeline = FeatureUnion(transformer_list=[</span><br><span class="line">        (<span class="string">"num_pipeline"</span>, num_pipeline),</span><br><span class="line">        (<span class="string">"cat_pipeline"</span>, cat_pipeline),</span><br><span class="line">    ])</span><br></pre></td></tr></table></figure>
<blockquote>
<p>译注:</p>
<p>如果你在上面代码中的<code>cat_pipeline</code>流水线使用<code>LabelBinarizer</code>转换器会导致执行错误，解决方案是用上文提到的<code>CategoricalEncoder</code>转换器来代替：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; cat_pipeline = Pipeline([</span><br><span class="line">&gt;         (<span class="string">'selector'</span>, DataFrameSelector(cat_attribs)),</span><br><span class="line">&gt;         (<span class="string">'cat_encoder'</span>, CategoricalEncoder(encoding=<span class="string">"onehot-dense"</span>)),</span><br><span class="line">&gt;     ])</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>你可以很简单地运行整个流水线：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_prepared = full_pipeline.fit_transform(housing)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_prepared</span><br><span class="line">array([[ <span class="number">0.73225807</span>, <span class="number">-0.67331551</span>,  <span class="number">0.58426443</span>, ...,  <span class="number">0.</span>        ,</span><br><span class="line">         <span class="number">0.</span>        ,  <span class="number">0.</span>        ],</span><br><span class="line">       [<span class="number">-0.99102923</span>,  <span class="number">1.63234656</span>, <span class="number">-0.92655887</span>, ...,  <span class="number">0.</span>        ,</span><br><span class="line">         <span class="number">0.</span>        ,  <span class="number">0.</span>        ],</span><br><span class="line">       [...]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_prepared.shape</span><br><span class="line">(<span class="number">16513</span>, <span class="number">17</span>)</span><br></pre></td></tr></table></figure>
<p>每个子流水线都以一个选择转换器开始：通过选择对应的属性（数值或分类）、丢弃其它的，来转换数据，并将输出<code>DataFrame</code>转变成一个 NumPy 数组。Scikit-Learn 没有工具来处理 Pandas<code>DataFrame</code>，因此我们需要写一个简单的自定义转换器来做这项工作：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> BaseEstimator, TransformerMixin</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DataFrameSelector</span><span class="params">(BaseEstimator, TransformerMixin)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, attribute_names)</span>:</span></span><br><span class="line">        self.attribute_names = attribute_names</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y=None)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> X[self.attribute_names].values</span><br></pre></td></tr></table></figure>
<h2 id="选择并训练模型"><a href="#选择并训练模型" class="headerlink" title="选择并训练模型"></a>选择并训练模型</h2><p>可到这一步了！你在前面限定了问题、获得了数据、探索了数据、采样了一个测试集、写了自动化的转换流水线来清理和为算法准备数据。现在，你已经准备好选择并训练一个机器学习模型了。</p>
<h3 id="在训练集上训练和评估"><a href="#在训练集上训练和评估" class="headerlink" title="在训练集上训练和评估"></a>在训练集上训练和评估</h3><p>好消息是基于前面的工作，接下来要做的比你想的要简单许多。像前一章那样，我们先来训练一个线性回归模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line">lin_reg = LinearRegression()</span><br><span class="line">lin_reg.fit(housing_prepared, housing_labels)</span><br></pre></td></tr></table></figure>
<p>完毕！你现在就有了一个可用的线性回归模型。用一些训练集中的实例做下验证：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>some_data = housing.iloc[:<span class="number">5</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>some_labels = housing_labels.iloc[:<span class="number">5</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>some_data_prepared = full_pipeline.transform(some_data)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(<span class="string">"Predictions:\t"</span>, lin_reg.predict(some_data_prepared))</span><br><span class="line">Predictions:     [ <span class="number">303104.</span>   <span class="number">44800.</span>  <span class="number">308928.</span>  <span class="number">294208.</span>  <span class="number">368704.</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(<span class="string">"Labels:\t\t"</span>, list(some_labels))</span><br><span class="line">Labels:         [<span class="number">359400.0</span>, <span class="number">69700.0</span>, <span class="number">302100.0</span>, <span class="number">301300.0</span>, <span class="number">351900.0</span>]</span><br></pre></td></tr></table></figure>
<p>行的通，尽管预测并不怎么准确（比如，第二个预测偏离了 50%！）。让我们使用 Scikit-Learn 的<code>mean_squared_error</code>函数，用全部训练集来计算下这个回归模型的 RMSE：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_predictions = lin_reg.predict(housing_prepared)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lin_mse = mean_squared_error(housing_labels, housing_predictions)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lin_rmse = np.sqrt(lin_mse)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lin_rmse</span><br><span class="line"><span class="number">68628.413493824875</span></span><br></pre></td></tr></table></figure>
<p>OK，有总比没有强，但显然结果并不好：大多数街区的<code>median_housing_values</code>位于 120000 到 265000 美元之间，因此预测误差 68628 美元不能让人满意。这是一个模型欠拟合训练数据的例子。当这种情况发生时，意味着特征没有提供足够多的信息来做出一个好的预测，或者模型并不强大。就像前一章看到的，修复欠拟合的主要方法是选择一个更强大的模型，给训练算法提供更好的特征，或去掉模型上的限制。这个模型还没有正则化，所以排除了最后一个选项。你可以尝试添加更多特征（比如，人口的对数值），但是首先让我们尝试一个更为复杂的模型，看看效果。</p>
<p>来训练一个<code>DecisionTreeRegressor</code>。这是一个强大的模型，可以发现数据中复杂的非线性关系（决策树会在第 6 章详细讲解）。代码看起来很熟悉：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"></span><br><span class="line">tree_reg = DecisionTreeRegressor()</span><br><span class="line">tree_reg.fit(housing_prepared, housing_labels)</span><br></pre></td></tr></table></figure>
<p>现在模型就训练好了，用训练集评估下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>housing_predictions = tree_reg.predict(housing_prepared)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tree_mse = mean_squared_error(housing_labels, housing_predictions)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tree_rmse = np.sqrt(tree_mse)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tree_rmse</span><br><span class="line"><span class="number">0.0</span></span><br></pre></td></tr></table></figure>
<p>等一下，发生了什么？没有误差？这个模型可能是绝对完美的吗？当然，更大可能性是这个模型严重过拟合数据。如何确定呢？如前所述，直到你准备运行一个具备足够信心的模型，都不要碰测试集，因此你需要使用训练集的部分数据来做训练，用一部分来做模型验证。</p>
<h3 id="使用交叉验证做更佳的评估"><a href="#使用交叉验证做更佳的评估" class="headerlink" title="使用交叉验证做更佳的评估"></a>使用交叉验证做更佳的评估</h3><p>评估决策树模型的一种方法是用函数<code>train_test_split</code>来分割训练集，得到一个更小的训练集和一个验证集，然后用更小的训练集来训练模型，用验证集来评估。这需要一定工作量，并不难而且也可行。</p>
<p>另一种更好的方法是使用 Scikit-Learn 的交叉验证功能。下面的代码采用了 K 折交叉验证（K-fold cross-validation）：它随机地将训练集分成十个不同的子集，成为“折”，然后训练评估决策树模型 10 次，每次选一个不用的折来做评估，用其它 9 个来做训练。结果是一个包含 10 个评分的数组：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line">scores = cross_val_score(tree_reg, housing_prepared, housing_labels,</span><br><span class="line">                         scoring=<span class="string">"neg_mean_squared_error"</span>, cv=<span class="number">10</span>)</span><br><span class="line">rmse_scores = np.sqrt(-scores)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>警告：Scikit-Learn 交叉验证功能期望的是效用函数（越大越好）而不是损失函数（越低越好），因此得分函数实际上与 MSE 相反（即负值），这就是为什么前面的代码在计算平方根之前先计算<code>-scores</code>。</p>
</blockquote>
<p>来看下结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">display_scores</span><span class="params">(scores)</span>:</span></span><br><span class="line"><span class="meta">... </span>    print(<span class="string">"Scores:"</span>, scores)</span><br><span class="line"><span class="meta">... </span>    print(<span class="string">"Mean:"</span>, scores.mean())</span><br><span class="line"><span class="meta">... </span>    print(<span class="string">"Standard deviation:"</span>, scores.std())</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>display_scores(tree_rmse_scores)</span><br><span class="line">Scores: [ <span class="number">74678.4916885</span>   <span class="number">64766.2398337</span>   <span class="number">69632.86942005</span>  <span class="number">69166.67693232</span></span><br><span class="line">          <span class="number">71486.76507766</span>  <span class="number">73321.65695983</span>  <span class="number">71860.04741226</span>  <span class="number">71086.32691692</span></span><br><span class="line">          <span class="number">76934.2726093</span>   <span class="number">69060.93319262</span>]</span><br><span class="line">Mean: <span class="number">71199.4280043</span></span><br><span class="line">Standard deviation: <span class="number">3202.70522793</span></span><br></pre></td></tr></table></figure>
<p>现在决策树就不像前面看起来那么好了。实际上，它看起来比线性回归模型还糟！注意到交叉验证不仅可以让你得到模型性能的评估，还能测量评估的准确性（即，它的标准差）。决策树的评分大约是 71200，通常波动有 ±3200。如果只有一个验证集，就得不到这些信息。但是交叉验证的代价是训练了模型多次，不可能总是这样。</p>
<p>让我们计算下线性回归模型的的相同分数，以做确保：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,</span><br><span class="line"><span class="meta">... </span>                             scoring=<span class="string">"neg_mean_squared_error"</span>, cv=<span class="number">10</span>)</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lin_rmse_scores = np.sqrt(-lin_scores)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>display_scores(lin_rmse_scores)</span><br><span class="line">Scores: [ <span class="number">70423.5893262</span>   <span class="number">65804.84913139</span>  <span class="number">66620.84314068</span>  <span class="number">72510.11362141</span></span><br><span class="line">          <span class="number">66414.74423281</span>  <span class="number">71958.89083606</span>  <span class="number">67624.90198297</span>  <span class="number">67825.36117664</span></span><br><span class="line">          <span class="number">72512.36533141</span>  <span class="number">68028.11688067</span>]</span><br><span class="line">Mean: <span class="number">68972.377566</span></span><br><span class="line">Standard deviation: <span class="number">2493.98819069</span></span><br></pre></td></tr></table></figure>
<p>判断没错：决策树模型过拟合很严重，它的性能比线性回归模型还差。</p>
<p>现在再尝试最后一个模型：<code>RandomForestRegressor</code>。第7章我们会看到，随机森林是通过用特征的随机子集训练许多决策树。在其它多个模型之上建立模型称为集成学习（Ensemble Learning），它是推进 ML 算法的一种好方法。我们会跳过大部分的代码，因为代码本质上和其它模型一样：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>forest_reg = RandomForestRegressor()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>forest_reg.fit(housing_prepared, housing_labels)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>[...]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>forest_rmse</span><br><span class="line"><span class="number">22542.396440343684</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>display_scores(forest_rmse_scores)</span><br><span class="line">Scores: [ <span class="number">53789.2879722</span>   <span class="number">50256.19806622</span>  <span class="number">52521.55342602</span>  <span class="number">53237.44937943</span></span><br><span class="line">          <span class="number">52428.82176158</span>  <span class="number">55854.61222549</span>  <span class="number">52158.02291609</span>  <span class="number">50093.66125649</span></span><br><span class="line">          <span class="number">53240.80406125</span>  <span class="number">52761.50852822</span>]</span><br><span class="line">Mean: <span class="number">52634.1919593</span></span><br><span class="line">Standard deviation: <span class="number">1576.20472269</span></span><br></pre></td></tr></table></figure>
<p>现在好多了：随机森林看起来很有希望。但是，训练集的评分仍然比验证集的评分低很多。解决过拟合可以通过简化模型，给模型加限制（即，规整化），或用更多的训练数据。在深入随机森林之前，你应该尝试下机器学习算法的其它类型模型（不同核心的支持向量机，神经网络，等等），不要在调节超参数上花费太多时间。目标是列出一个可能模型的列表（两到五个）。</p>
<blockquote>
<p>提示：你要保存每个试验过的模型，以便后续可以再用。要确保有超参数和训练参数，以及交叉验证评分，和实际的预测值。这可以让你比较不同类型模型的评分，还可以比较误差种类。你可以用 Python 的模块<code>pickle</code>，非常方便地保存 Scikit-Learn 模型，或使用<code>sklearn.externals.joblib</code>，后者序列化大 NumPy 数组更有效率：</p>
</blockquote>
<blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; <span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> joblib</span><br><span class="line">&gt; </span><br><span class="line">&gt; joblib.dump(my_model, <span class="string">"my_model.pkl"</span>)</span><br><span class="line">&gt; <span class="comment"># 然后</span></span><br><span class="line">&gt; my_model_loaded = joblib.load(<span class="string">"my_model.pkl"</span>)</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<h2 id="模型微调"><a href="#模型微调" class="headerlink" title="模型微调"></a>模型微调</h2><p>假设你现在有了一个列表，列表里有几个有希望的模型。你现在需要对它们进行微调。让我们来看几种微调的方法。</p>
<h3 id="网格搜索"><a href="#网格搜索" class="headerlink" title="网格搜索"></a>网格搜索</h3><p>微调的一种方法是手工调整超参数，直到找到一个好的超参数组合。这么做的话会非常冗长，你也可能没有时间探索多种组合。</p>
<p>你应该使用 Scikit-Learn 的<code>GridSearchCV</code>来做这项搜索工作。你所需要做的是告诉<code>GridSearchCV</code>要试验有哪些超参数，要试验什么值，<code>GridSearchCV</code>就能用交叉验证试验所有可能超参数值的组合。例如，下面的代码搜索了<code>RandomForestRegressor</code>超参数值的最佳组合：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"></span><br><span class="line">param_grid = [</span><br><span class="line">    &#123;<span class="string">'n_estimators'</span>: [<span class="number">3</span>, <span class="number">10</span>, <span class="number">30</span>], <span class="string">'max_features'</span>: [<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>]&#125;,</span><br><span class="line">    &#123;<span class="string">'bootstrap'</span>: [<span class="keyword">False</span>], <span class="string">'n_estimators'</span>: [<span class="number">3</span>, <span class="number">10</span>], <span class="string">'max_features'</span>: [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]&#125;,</span><br><span class="line">  ]</span><br><span class="line"></span><br><span class="line">forest_reg = RandomForestRegressor()</span><br><span class="line"></span><br><span class="line">grid_search = GridSearchCV(forest_reg, param_grid, cv=<span class="number">5</span>,</span><br><span class="line">                           scoring=<span class="string">'neg_mean_squared_error'</span>)</span><br><span class="line"></span><br><span class="line">grid_search.fit(housing_prepared, housing_labels)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>当你不能确定超参数该有什么值，一个简单的方法是尝试连续的 10 的幂（如果想要一个粒度更小的搜寻，可以用更小的数，就像在这个例子中对超参数<code>n_estimators</code>做的）。</p>
</blockquote>
<p><code>param_grid</code>告诉 Scikit-Learn 首先评估所有的列在第一个<code>dict</code>中的<code>n_estimators</code>和<code>max_features</code>的<code>3 × 4 = 12</code>种组合（不用担心这些超参数的含义，会在第 7 章中解释）。然后尝试第二个<code>dict</code>中超参数的<code>2 × 3 = 6</code>种组合，这次会将超参数<code>bootstrap</code>设为<code>False</code>而不是<code>True</code>（后者是该超参数的默认值）。</p>
<p>总之，网格搜索会探索<code>12 + 6 = 18</code>种<code>RandomForestRegressor</code>的超参数组合，会训练每个模型五次（因为用的是五折交叉验证）。换句话说，训练总共有<code>18 × 5 = 90</code>轮！K 折将要花费大量时间，完成后，你就能获得参数的最佳组合，如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>grid_search.best_params_</span><br><span class="line">&#123;<span class="string">'max_features'</span>: <span class="number">6</span>, <span class="string">'n_estimators'</span>: <span class="number">30</span>&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>提示：因为 30 是<code>n_estimators</code>的最大值，你也应该估计更高的值，因为评估的分数可能会随<code>n_estimators</code>的增大而持续提升。</p>
</blockquote>
<p>你还能直接得到最佳的估计器：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>grid_search.best_estimator_</span><br><span class="line">RandomForestRegressor(bootstrap=<span class="keyword">True</span>, criterion=<span class="string">'mse'</span>, max_depth=<span class="keyword">None</span>,</span><br><span class="line">           max_features=<span class="number">6</span>, max_leaf_nodes=<span class="keyword">None</span>, min_samples_leaf=<span class="number">1</span>,</span><br><span class="line">           min_samples_split=<span class="number">2</span>, min_weight_fraction_leaf=<span class="number">0.0</span>,</span><br><span class="line">           n_estimators=<span class="number">30</span>, n_jobs=<span class="number">1</span>, oob_score=<span class="keyword">False</span>, random_state=<span class="keyword">None</span>,</span><br><span class="line">           verbose=<span class="number">0</span>, warm_start=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：如果<code>GridSearchCV</code>是以（默认值）<code>refit=True</code>开始运行的，则一旦用交叉验证找到了最佳的估计器，就会在整个训练集上重新训练。这是一个好方法，因为用更多数据训练会提高性能。</p>
</blockquote>
<p>当然，也可以得到评估得分：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>cvres = grid_search.cv_results_</span><br><span class="line"><span class="meta">... </span><span class="keyword">for</span> mean_score, params <span class="keyword">in</span> zip(cvres[<span class="string">"mean_test_score"</span>], cvres[<span class="string">"params"</span>]):</span><br><span class="line"><span class="meta">... </span>    print(np.sqrt(-mean_score), params)</span><br><span class="line">...</span><br><span class="line"><span class="number">64912.0351358</span> &#123;<span class="string">'max_features'</span>: <span class="number">2</span>, <span class="string">'n_estimators'</span>: <span class="number">3</span>&#125;</span><br><span class="line"><span class="number">55535.2786524</span> &#123;<span class="string">'max_features'</span>: <span class="number">2</span>, <span class="string">'n_estimators'</span>: <span class="number">10</span>&#125;</span><br><span class="line"><span class="number">52940.2696165</span> &#123;<span class="string">'max_features'</span>: <span class="number">2</span>, <span class="string">'n_estimators'</span>: <span class="number">30</span>&#125;</span><br><span class="line"><span class="number">60384.0908354</span> &#123;<span class="string">'max_features'</span>: <span class="number">4</span>, <span class="string">'n_estimators'</span>: <span class="number">3</span>&#125;</span><br><span class="line"><span class="number">52709.9199934</span> &#123;<span class="string">'max_features'</span>: <span class="number">4</span>, <span class="string">'n_estimators'</span>: <span class="number">10</span>&#125;</span><br><span class="line"><span class="number">50503.5985321</span> &#123;<span class="string">'max_features'</span>: <span class="number">4</span>, <span class="string">'n_estimators'</span>: <span class="number">30</span>&#125;</span><br><span class="line"><span class="number">59058.1153485</span> &#123;<span class="string">'max_features'</span>: <span class="number">6</span>, <span class="string">'n_estimators'</span>: <span class="number">3</span>&#125;</span><br><span class="line"><span class="number">52172.0292957</span> &#123;<span class="string">'max_features'</span>: <span class="number">6</span>, <span class="string">'n_estimators'</span>: <span class="number">10</span>&#125;</span><br><span class="line"><span class="number">49958.9555932</span> &#123;<span class="string">'max_features'</span>: <span class="number">6</span>, <span class="string">'n_estimators'</span>: <span class="number">30</span>&#125;</span><br><span class="line"><span class="number">59122.260006</span> &#123;<span class="string">'max_features'</span>: <span class="number">8</span>, <span class="string">'n_estimators'</span>: <span class="number">3</span>&#125;</span><br><span class="line"><span class="number">52441.5896087</span> &#123;<span class="string">'max_features'</span>: <span class="number">8</span>, <span class="string">'n_estimators'</span>: <span class="number">10</span>&#125;</span><br><span class="line"><span class="number">50041.4899416</span> &#123;<span class="string">'max_features'</span>: <span class="number">8</span>, <span class="string">'n_estimators'</span>: <span class="number">30</span>&#125;</span><br><span class="line"><span class="number">62371.1221202</span> &#123;<span class="string">'bootstrap'</span>: <span class="keyword">False</span>, <span class="string">'max_features'</span>: <span class="number">2</span>, <span class="string">'n_estimators'</span>: <span class="number">3</span>&#125;</span><br><span class="line"><span class="number">54572.2557534</span> &#123;<span class="string">'bootstrap'</span>: <span class="keyword">False</span>, <span class="string">'max_features'</span>: <span class="number">2</span>, <span class="string">'n_estimators'</span>: <span class="number">10</span>&#125;</span><br><span class="line"><span class="number">59634.0533132</span> &#123;<span class="string">'bootstrap'</span>: <span class="keyword">False</span>, <span class="string">'max_features'</span>: <span class="number">3</span>, <span class="string">'n_estimators'</span>: <span class="number">3</span>&#125;</span><br><span class="line"><span class="number">52456.0883904</span> &#123;<span class="string">'bootstrap'</span>: <span class="keyword">False</span>, <span class="string">'max_features'</span>: <span class="number">3</span>, <span class="string">'n_estimators'</span>: <span class="number">10</span>&#125;</span><br><span class="line"><span class="number">58825.665239</span> &#123;<span class="string">'bootstrap'</span>: <span class="keyword">False</span>, <span class="string">'max_features'</span>: <span class="number">4</span>, <span class="string">'n_estimators'</span>: <span class="number">3</span>&#125;</span><br><span class="line"><span class="number">52012.9945396</span> &#123;<span class="string">'bootstrap'</span>: <span class="keyword">False</span>, <span class="string">'max_features'</span>: <span class="number">4</span>, <span class="string">'n_estimators'</span>: <span class="number">10</span>&#125;</span><br></pre></td></tr></table></figure>
<p>在这个例子中，我们通过设定超参数<code>max_features</code>为 6，<code>n_estimators</code>为 30，得到了最佳方案。对这个组合，RMSE 的值是 49959，这比之前使用默认的超参数的值（52634）要稍微好一些。祝贺你，你成功地微调了最佳模型！</p>
<blockquote>
<p>提示：不要忘记，你可以像超参数一样处理数据准备的步骤。例如，网格搜索可以自动判断是否添加一个你不确定的特征（比如，使用转换器<code>CombinedAttributesAdder</code>的超参数<code>add_bedrooms_per_room</code>）。它还能用相似的方法来自动找到处理异常值、缺失特征、特征选择等任务的最佳方法。</p>
</blockquote>
<h3 id="随机搜索"><a href="#随机搜索" class="headerlink" title="随机搜索"></a>随机搜索</h3><p>当探索相对较少的组合时，就像前面的例子，网格搜索还可以。但是当超参数的搜索空间很大时，最好使用<code>RandomizedSearchCV</code>。这个类的使用方法和类<code>GridSearchCV</code>很相似，但它不是尝试所有可能的组合，而是通过选择每个超参数的一个随机值的特定数量的随机组合。这个方法有两个优点：</p>
<ul>
<li><p>如果你让随机搜索运行，比如 1000 次，它会探索每个超参数的 1000 个不同的值（而不是像网格搜索那样，只搜索每个超参数的几个值）。</p>
</li>
<li><p>你可以方便地通过设定搜索次数，控制超参数搜索的计算量。</p>
</li>
</ul>
<h3 id="集成方法"><a href="#集成方法" class="headerlink" title="集成方法"></a>集成方法</h3><p>另一种微调系统的方法是将表现最好的模型组合起来。组合（集成）之后的性能通常要比单独的模型要好（就像随机森林要比单独的决策树要好），特别是当单独模型的误差类型不同时。我们会在第7章更深入地讲解这点。</p>
<h3 id="分析最佳模型和它们的误差"><a href="#分析最佳模型和它们的误差" class="headerlink" title="分析最佳模型和它们的误差"></a>分析最佳模型和它们的误差</h3><p>通过分析最佳模型，常常可以获得对问题更深的了解。比如，<code>RandomForestRegressor</code>可以指出每个属性对于做出准确预测的相对重要性：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>feature_importances = grid_search.best_estimator_.feature_importances_</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>feature_importances</span><br><span class="line">array([  <span class="number">7.14156423e-02</span>,   <span class="number">6.76139189e-02</span>,   <span class="number">4.44260894e-02</span>,</span><br><span class="line">         <span class="number">1.66308583e-02</span>,   <span class="number">1.66076861e-02</span>,   <span class="number">1.82402545e-02</span>,</span><br><span class="line">         <span class="number">1.63458761e-02</span>,   <span class="number">3.26497987e-01</span>,   <span class="number">6.04365775e-02</span>,</span><br><span class="line">         <span class="number">1.13055290e-01</span>,   <span class="number">7.79324766e-02</span>,   <span class="number">1.12166442e-02</span>,</span><br><span class="line">         <span class="number">1.53344918e-01</span>,   <span class="number">8.41308969e-05</span>,   <span class="number">2.68483884e-03</span>,</span><br><span class="line">         <span class="number">3.46681181e-03</span>])</span><br></pre></td></tr></table></figure>
<p>将重要性分数和属性名放到一起：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>extra_attribs = [<span class="string">"rooms_per_hhold"</span>, <span class="string">"pop_per_hhold"</span>, <span class="string">"bedrooms_per_room"</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cat_one_hot_attribs = list(encoder.classes_)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>attributes = num_attribs + extra_attribs + cat_one_hot_attribs</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sorted(zip(feature_importances,attributes), reverse=<span class="keyword">True</span>)</span><br><span class="line">[(<span class="number">0.32649798665134971</span>, <span class="string">'median_income'</span>),</span><br><span class="line"> (<span class="number">0.15334491760305854</span>, <span class="string">'INLAND'</span>),</span><br><span class="line"> (<span class="number">0.11305529021187399</span>, <span class="string">'pop_per_hhold'</span>),</span><br><span class="line"> (<span class="number">0.07793247662544775</span>, <span class="string">'bedrooms_per_room'</span>),</span><br><span class="line"> (<span class="number">0.071415642259275158</span>, <span class="string">'longitude'</span>),</span><br><span class="line"> (<span class="number">0.067613918945568688</span>, <span class="string">'latitude'</span>),</span><br><span class="line"> (<span class="number">0.060436577499703222</span>, <span class="string">'rooms_per_hhold'</span>),</span><br><span class="line"> (<span class="number">0.04442608939578685</span>, <span class="string">'housing_median_age'</span>),</span><br><span class="line"> (<span class="number">0.018240254462909437</span>, <span class="string">'population'</span>),</span><br><span class="line"> (<span class="number">0.01663085833886218</span>, <span class="string">'total_rooms'</span>),</span><br><span class="line"> (<span class="number">0.016607686091288865</span>, <span class="string">'total_bedrooms'</span>),</span><br><span class="line"> (<span class="number">0.016345876147580776</span>, <span class="string">'households'</span>),</span><br><span class="line"> (<span class="number">0.011216644219017424</span>, <span class="string">'&lt;1H OCEAN'</span>),</span><br><span class="line"> (<span class="number">0.0034668118081117387</span>, <span class="string">'NEAR OCEAN'</span>),</span><br><span class="line"> (<span class="number">0.0026848388432755429</span>, <span class="string">'NEAR BAY'</span>),</span><br><span class="line"> (<span class="number">8.4130896890070617e-05</span>, <span class="string">'ISLAND'</span>)]</span><br></pre></td></tr></table></figure>
<p>有了这个信息，你就可以丢弃一些不那么重要的特征（比如，显然只要一个<code>ocean_proximity</code>的类型（INLAND）就够了，所以可以丢弃掉其它的）。</p>
<p>你还应该看一下系统犯的误差，搞清为什么会有些误差，以及如何改正问题（添加更多的特征，或相反，去掉没有什么信息的特征，清洗异常值等等）。</p>
<h3 id="用测试集评估系统"><a href="#用测试集评估系统" class="headerlink" title="用测试集评估系统"></a>用测试集评估系统</h3><p>调节完系统之后，你终于有了一个性能足够好的系统。现在就可以用测试集评估最后的模型了。这个过程没有什么特殊的：从测试集得到预测值和标签，运行<code>full_pipeline</code>转换数据（调用<code>transform()</code>，而不是<code>fit_transform()</code>！），再用测试集评估最终模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">final_model = grid_search.best_estimator_</span><br><span class="line"></span><br><span class="line">X_test = strat_test_set.drop(<span class="string">"median_house_value"</span>, axis=<span class="number">1</span>)</span><br><span class="line">y_test = strat_test_set[<span class="string">"median_house_value"</span>].copy()</span><br><span class="line"></span><br><span class="line">X_test_prepared = full_pipeline.transform(X_test)</span><br><span class="line"></span><br><span class="line">final_predictions = final_model.predict(X_test_prepared)</span><br><span class="line"></span><br><span class="line">final_mse = mean_squared_error(y_test, final_predictions)</span><br><span class="line">final_rmse = np.sqrt(final_mse)   <span class="comment"># =&gt; evaluates to 48,209.6</span></span><br></pre></td></tr></table></figure>
<p>评估结果通常要比交叉验证的效果差一点，如果你之前做过很多超参数微调（因为你的系统在验证集上微调，得到了不错的性能，通常不会在未知的数据集上有同样好的效果）。这个例子不属于这种情况，但是当发生这种情况时，你一定要忍住不要调节超参数，使测试集的效果变好；这样的提升不能推广到新数据上。</p>
<p>然后就是项目的预上线阶段：你需要展示你的方案（重点说明学到了什么、做了什么、没做什么、做过什么假设、系统的限制是什么，等等），记录下所有事情，用漂亮的图表和容易记住的表达（比如，“收入中位数是房价最重要的预测量”）做一次精彩的展示。</p>
<h2 id="启动、监控、维护系统"><a href="#启动、监控、维护系统" class="headerlink" title="启动、监控、维护系统"></a>启动、监控、维护系统</h2><p>很好，你被允许启动系统了！你需要为实际生产做好准备，特别是接入输入数据源，并编写测试。</p>
<p>你还需要编写监控代码，以固定间隔检测系统的实时表现，当发生下降时触发报警。这对于捕获突然的系统崩溃和性能下降十分重要。做监控很常见，是因为模型会随着数据的演化而性能下降，除非模型用新数据定期训练。</p>
<p>评估系统的表现需要对预测值采样并进行评估。这通常需要人来分析。分析者可能是领域专家，或者是众包平台（比如 Amazon Mechanical Turk 或 CrowdFlower）的工人。不管采用哪种方法，你都需要将人工评估的流水线植入系统。</p>
<p>你还要评估系统输入数据的质量。有时因为低质量的信号（比如失灵的传感器发送随机值，或另一个团队的输出停滞），系统的表现会逐渐变差，但可能需要一段时间，系统的表现才能下降到一定程度，触发警报。如果监测了系统的输入，你就可能尽量早的发现问题。对于线上学习系统，监测输入数据是非常重要的。</p>
<p>最后，你可能想定期用新数据训练模型。你应该尽可能自动化这个过程。如果不这么做，非常有可能你需要每隔至少六个月更新模型，系统的表现就会产生严重波动。如果你的系统是一个线上学习系统，你需要定期保存系统状态快照，好能方便地回滚到之前的工作状态。</p>
<h2 id="实践！"><a href="#实践！" class="headerlink" title="实践！"></a>实践！</h2><p>希望这一章能告诉你机器学习项目是什么样的，你能用学到的工具训练一个好系统。你已经看到，大部分的工作是数据准备步骤、搭建监测工具、建立人为评估的流水线和自动化定期模型训练，当然，最好能了解整个过程、熟悉三或四种算法，而不是在探索高级算法上浪费全部时间，导致在全局上的时间不够。</p>
<p>因此，如果你还没这样做，现在最好拿起台电脑，选择一个感兴趣的数据集，将整个流程从头到尾完成一遍。一个不错的着手开始的地点是竞赛网站，比如 <a href="http://kaggle.com/" target="_blank" rel="noopener">http://kaggle.com/</a>：你会得到一个数据集，一个目标，以及分享经验的人。</p>
<h2 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h2><p>使用本章的房产数据集：</p>
<ol>
<li><p>尝试一个支持向量机回归器（<code>sklearn.svm.SVR</code>），使用多个超参数，比如<code>kernel=&quot;linear&quot;</code>（多个超参数<code>C</code>值）。现在不用担心这些超参数是什么含义。最佳的<code>SVR</code>预测表现如何？</p>
</li>
<li><p>尝试用<code>RandomizedSearchCV</code>替换<code>GridSearchCV</code>。</p>
</li>
<li><p>尝试在准备流水线中添加一个只选择最重要属性的转换器。</p>
</li>
<li><p>尝试创建一个单独的可以完成数据准备和最终预测的流水线。</p>
</li>
<li><p>使用<code>GridSearchCV</code>自动探索一些准备过程中的候选项。</p>
</li>
</ol>
<p>练习题答案可以在<a href="https://github.com/ageron/handson-ml" target="_blank" rel="noopener">线上的 Jupyter notebook</a> 找到。</p>

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div></div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏~</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.jpg" alt="朱政烨 微信支付"/>
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/alipay.jpg" alt="朱政烨 支付宝"/>
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      

      
      
        <div class="post-widgets">
        

        

        
          
          <div id="needsharebutton-postbottom">
            <span class="btn">
              <i class="fa fa-share-alt" aria-hidden="true"></i>
            </span>
          </div>
        
        </div>
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/06/04/001/" rel="next" title="kaggle入门 | Digit Recognizer准确度100%">
                <i class="fa fa-chevron-left"></i> kaggle入门 | Digit Recognizer准确度100%
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/06/05/1.机器学习概览/" rel="prev" title="机器学习笔记|第1章 机器学习概览">
                机器学习笔记|第1章 机器学习概览 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
    </div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="朱政烨" />
            
              <p class="site-author-name" itemprop="name">朱政烨</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/zzy99" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:80431395@qq.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="http://www.zhihu.com/people/_zzy_" target="_blank" title="知乎">
                      
                        <i class="fa fa-fw fa-globe"></i>知乎</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#使用真实数据"><span class="nav-number">1.</span> <span class="nav-text">使用真实数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#项目概览"><span class="nav-number">2.</span> <span class="nav-text">项目概览</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#划定问题"><span class="nav-number">2.1.</span> <span class="nav-text">划定问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#选择性能指标"><span class="nav-number">2.2.</span> <span class="nav-text">选择性能指标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#核实假设"><span class="nav-number">2.3.</span> <span class="nav-text">核实假设</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#获取数据"><span class="nav-number">3.</span> <span class="nav-text">获取数据</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#创建工作空间"><span class="nav-number">3.1.</span> <span class="nav-text">创建工作空间</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#下载数据"><span class="nav-number">3.2.</span> <span class="nav-text">下载数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#快速查看数据结构"><span class="nav-number">3.3.</span> <span class="nav-text">快速查看数据结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建测试集"><span class="nav-number">3.4.</span> <span class="nav-text">创建测试集</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#数据探索和可视化、发现规律"><span class="nav-number">4.</span> <span class="nav-text">数据探索和可视化、发现规律</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#地理数据可视化"><span class="nav-number">4.1.</span> <span class="nav-text">地理数据可视化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#查找关联"><span class="nav-number">4.2.</span> <span class="nav-text">查找关联</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#属性组合试验"><span class="nav-number">4.3.</span> <span class="nav-text">属性组合试验</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#为机器学习算法准备数据"><span class="nav-number">5.</span> <span class="nav-text">为机器学习算法准备数据</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#数据清洗"><span class="nav-number">5.1.</span> <span class="nav-text">数据清洗</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#处理文本和类别属性"><span class="nav-number">5.2.</span> <span class="nav-text">处理文本和类别属性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#自定义转换器"><span class="nav-number">5.3.</span> <span class="nav-text">自定义转换器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#特征缩放"><span class="nav-number">5.4.</span> <span class="nav-text">特征缩放</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#转换流水线"><span class="nav-number">5.5.</span> <span class="nav-text">转换流水线</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#选择并训练模型"><span class="nav-number">6.</span> <span class="nav-text">选择并训练模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#在训练集上训练和评估"><span class="nav-number">6.1.</span> <span class="nav-text">在训练集上训练和评估</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#使用交叉验证做更佳的评估"><span class="nav-number">6.2.</span> <span class="nav-text">使用交叉验证做更佳的评估</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模型微调"><span class="nav-number">7.</span> <span class="nav-text">模型微调</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#网格搜索"><span class="nav-number">7.1.</span> <span class="nav-text">网格搜索</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#随机搜索"><span class="nav-number">7.2.</span> <span class="nav-text">随机搜索</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#集成方法"><span class="nav-number">7.3.</span> <span class="nav-text">集成方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分析最佳模型和它们的误差"><span class="nav-number">7.4.</span> <span class="nav-text">分析最佳模型和它们的误差</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#用测试集评估系统"><span class="nav-number">7.5.</span> <span class="nav-text">用测试集评估系统</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#启动、监控、维护系统"><span class="nav-number">8.</span> <span class="nav-text">启动、监控、维护系统</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#实践！"><span class="nav-number">9.</span> <span class="nav-text">实践！</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#练习"><span class="nav-number">10.</span> <span class="nav-text">练习</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">朱政烨</span>

  
</div>

<span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span>
<script>
    var now = new Date(); 
    function createtime() { 
        var grt= new Date("06/04/2018 21:00:00");//此处修改你的建站时间或者网站上线时间 
        now.setTime(now.getTime()+250); 
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); 
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); 
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); 
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;} 
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); 
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;} 
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 "; 
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒"; 
    } 
setInterval("createtime()",250);
</script>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  









  



  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  

  
  
    <script id="ribbon" type="text/javascript" size="100" alpha="0.2"  zIndex="-1" src="/lib/canvas-ribbon/canvas-ribbon.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  










  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: true,
        appId: 'm5iyr4lfjTptIqNLHmUn3nk9-gzGzoHsz',
        appKey: 'TajMgponUPGPQAnUzIac21tM',
        placeholder: 'ヾﾉ≧∀≦)o来啊，快活啊!',
        avatar:'wavatar',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  
  
  <link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css">

  
  
  <script src="/lib/needsharebutton/needsharebutton.js"></script>

  <script>
    
      pbOptions = {};
      
          pbOptions.iconStyle = "default";
      
          pbOptions.boxForm = "horizontal";
      
          pbOptions.position = "bottomCenter";
      
          pbOptions.networks = "Weibo,Wechat,QQZone,Twitter,Facebook";
      
      new needShareButton('#needsharebutton-postbottom', pbOptions);
    
    
  </script>

  

  

  

  

 <!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/click.js"></script>
</body>
</html>
